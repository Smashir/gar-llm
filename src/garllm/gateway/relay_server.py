#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
relay_server.py â€” GAR-LLM Gateway Relay Server (env_utilsçµ±åˆç‰ˆ)
-----------------------------------------------------------
OpenAI API äº’æ›ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã—ã€
style_layer / context_layer / persona_layer ã¨é€£æºã—ã¦
ä¼šè©±ã‚¹ã‚¿ã‚¤ãƒ«ã¨ãƒšãƒ«ã‚½ãƒŠã‚’è‡ªå‹•åˆ¶å¾¡ã—ã¾ã™ã€‚

ç‰¹å¾´:
- OpenAI äº’æ› /v1/chat/completions ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œ
- ãƒšãƒ«ã‚½ãƒŠãŒå­˜åœ¨ã—ãªã„å ´åˆã€è‡ªå‹•ç”Ÿæˆã‚’ãƒˆãƒªã‚¬ãƒ¼
- context_controller ã¨ style_modulator ã‚’çµ±åˆå‘¼ã³å‡ºã—
- env_utils.py ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã‚’ä¸€å…ƒç®¡ç†

èµ·å‹•ä¾‹:
    python3 relay_server.py --host 0.0.0.0 --port 8081

APIåˆ©ç”¨ä¾‹:
    curl -X POST http://localhost:8081/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gar-llm",
        "messages": [
          {"role": "system", "content": "ã‚ãªãŸã¯ç¹”ç”°ä¿¡é•·ã§ã™ã€‚"},
          {"role": "user", "content": "ã‚ˆãã‚‚ã‚„ã£ã¦ãã‚ŒãŸãª"}
        ],
        "persona": "ç¹”ç”°ä¿¡é•·",
        "intensity": 0.8,
        "verbose": true
      }' | jq .
"""

import re
import os
import sys
import json
import time
import subprocess
from pathlib import Path
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse

import garllm
from garllm.utils.env_utils import get_data_path, ensure_data_dirs  # âœ… env_utilsçµ±åˆ
from garllm.style_layer.response_modulator import modulate_response
from garllm.utils.logger import get_logger
from garllm.utils.llm_client import request_llm


# ============================================================
# GAR ç’°å¢ƒãƒ‘ã‚¹è¨­å®š
# ============================================================
#GAR_ROOT = Path(os.path.expanduser("~/modules/gar-llm/src"))
#sys.path.append(str(GAR_ROOT))

# garllm ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ«ãƒ¼ãƒˆã¨ã—ã¦ä½¿ã†
GAR_ROOT = Path(garllm.__file__).resolve().parent
# ã‚‚ã— src é…ä¸‹ãŒã‚ã‚‹å ´åˆã¯è‡ªå‹•ã§1éšå±¤ä¸ŠãŒã‚‹
if (GAR_ROOT / "garllm").exists():
    GAR_ROOT = GAR_ROOT / "garllm"

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆæœŸåŒ–
ensure_data_dirs()
PERSONA_DIR = Path(get_data_path("personas"))
THOUGHT_DIR = Path(get_data_path("thoughts"))
SEMANTIC_DIR = Path(get_data_path("semantic"))
RETRIEVED_DIR = Path(get_data_path("retrieved"))
CLEANED_DIR = Path(get_data_path("cleaned"))
CONDENSED_DIR = Path(get_data_path("condensed"))

# ============================================================
# ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆåˆæœŸå€¤ã¯INFOã€mainã§ä¸Šæ›¸ãï¼‰
# ============================================================

logger = get_logger("relay_server", level="INFO", to_console=False)

# ============================================================
# FastAPI è¨­å®š
# ============================================================
app = FastAPI(title="GAR-LLM Relay Server", version="1.2.0")

# ============================================================
# è£œåŠ©é–¢æ•°ç¾¤
# ============================================================

def _is_internal_prompt(message_text: str) -> bool:
    patterns = ["### Task:", "### Chat History:", "### Output:", "### Guidelines:"]
    return any(p in message_text for p in patterns)

def _state_path_for(persona_name: str) -> str:
    """~/data/personas/state_<persona>.json ã‚’è¿”ã™"""
    base = Path(get_data_path("personas"))
    base.mkdir(parents=True, exist_ok=True)
    return str(base / f"state_{persona_name}.json")

def _persona_path_for(persona_name: str) -> str:
    """~/data/personas/persona_<persona>.json ã‚’è¿”ã™ï¼ˆå¿…è¦ãªã‚‰ä½¿ç”¨ï¼‰"""
    base = Path(get_data_path("personas"))
    return str(base / f"persona_{persona_name}.json")

def _load_state(persona_name: str) -> dict:
    """å­˜åœ¨ã—ãªã‘ã‚Œã°æœ€å°åˆæœŸå€¤ã‚’è¿”ã™ï¼ˆcontext_controllerã®åˆæœŸå½¢ã«åˆã‚ã›ã‚‹ï¼‰"""
    p = _state_path_for(persona_name)
    if os.path.exists(p):
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f)
    # ã‹ã‚‰ã®åˆæœŸï¼ˆrelationsã¯ãƒ¦ãƒ¼ã‚¶ã®ã¿ã§0åŸ‹ã‚ã€emotion_axesã¯8è»¸0ï¼‰
    rel_axes = {k: 0.0 for k in ["Trust","Familiarity","Hostility","Dominance","Empathy","Instrumentality"]}
    emo_axes = {k: 0.0 for k in ["joy","trust","fear","surprise","sadness","disgust","anger","anticipation"]}
    return {"relations":{"ãƒ¦ãƒ¼ã‚¶":rel_axes},"emotion_axes":emo_axes,"phase_weights":{}}

def _save_state(persona_name: str, state: dict) -> None:
    p = _state_path_for(persona_name)
    os.makedirs(os.path.dirname(p), exist_ok=True)
    with open(p, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def _extract_user_axes(relations: dict | None) -> dict | None:
    """
    relations ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶â‡„personaã€ã®è»¸ã ã‘ã‚’å–ã‚Šå‡ºã—ã¦è¿”ã™ã€‚
    è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° Noneã€‚
    """
    if not isinstance(relations, dict):
        return None
    # ã‚ˆãä½¿ã†ã‚­ãƒ¼ã®è¡¨è¨˜ã‚†ã‚Œã‚’å¸å
    for k in ("ãƒ¦ãƒ¼ã‚¶", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "user", "User"):
        axes = relations.get(k)
        if isinstance(axes, dict):
            return axes
    return None

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£: å…ˆé ­ã® {name}: / {name}ï¼š ã‚’å…¨éƒ¨ã¯ãŒã—ã¦ã€å¿…è¦ãªã‚‰1å›ã ã‘ä»˜ã‘ã‚‹
def _normalize_persona_prefix(text: str, persona_name: str, keep_one: bool) -> str:
    if not text:
        return text
    # ^(ç¹”ç”°ä¿¡é•·\s*[:ï¼š]\s*)+ ã‚’å…¨å‰Šé™¤
    pattern = re.compile(rf'^(?:{re.escape(persona_name)}\s*[:ï¼š]\s*)+', re.UNICODE)
    cleaned = pattern.sub('', text.strip())
    return f"{persona_name}: {cleaned}" if keep_one else cleaned


def _run_step(script_name: str, args: list[str]):
    """å„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’é †ã«èµ·å‹•"""

    if script_name == "persona_generator.py":
        script_path = GAR_ROOT / "persona_layer" / script_name
    else:
        script_path = GAR_ROOT / "context_layer" / script_name
        
    if not script_path.exists():
        print(f"[WARN] Missing script: {script_path}")
        return False


    logger.info(f"Running {script_name} {' '.join(args)}", file=sys.stderr)

    result = subprocess.run(["python3", str(script_path)] + args, capture_output=True, text=True)
    if result.returncode != 0:
        logger.error(f"Step failed: {script_name}\n{result.stderr}")
        return False
    return True


def _auto_generate_persona(persona_name: str) -> bool:
    """retriever â†’ cleaner â†’ condenser â†’ semantic_condenser â†’ thought_profiler â†’ persona_generator ã‚’é †æ¬¡èµ·å‹•"""
    logger.info(f"Persona '{persona_name}' not found, auto-generation triggered.", file=sys.stderr)

    steps = [
        ("retriever.py", ["--query", persona_name, "--output", str(RETRIEVED_DIR / f"retrieved_{persona_name}.json")]),
        ("cleaner.py", ["--input", str(RETRIEVED_DIR / f"retrieved_{persona_name}.json"),
                        "--output", str(CLEANED_DIR / f"cleaned_{persona_name}.json")]),
        ("condenser.py", ["--input", str(CLEANED_DIR / f"cleaned_{persona_name}.json"),
                          "--output", str(CONDENSED_DIR / f"condensed_{persona_name}.json")]),
        ("semantic_condenser.py", ["--input", str(CONDENSED_DIR / f"condensed_{persona_name}.json"),
                                   "--output", str(SEMANTIC_DIR / f"semantic_{persona_name}.json")]),
        ("thought_profiler.py", ["--input", str(SEMANTIC_DIR / f"semantic_{persona_name}.json"),
                                 "--output", str(THOUGHT_DIR / f"thought_{persona_name}.json"),
                                 "--persona", persona_name]),
        ("persona_generator.py", ["--input", str(THOUGHT_DIR / f"thought_{persona_name}.json"),
                                    "--persona", persona_name])
    ]

    for script, args in steps:
        if not _run_step(script, args):
            logger.error(f"Persona generation failed at step: {script}", file=sys.stderr)
            return False

    persona_path = PERSONA_DIR / f"persona_{persona_name}.json"
    if persona_path.exists():
        logger.info(f"Persona successfully generated: {persona_name}", file=sys.stderr)
        return True
    else:
        logger.error(f"Persona file not found after generation: {persona_path}", file=sys.stderr)
        return False


def _ensure_persona_exists(persona_name: str):
    """ãƒšãƒ«ã‚½ãƒŠãŒå­˜åœ¨ã—ãªã„å ´åˆã€è‡ªå‹•ç”Ÿæˆã‚’è¡Œã†"""
    persona_path = PERSONA_DIR / f"persona_{persona_name}.json"
    if persona_path.exists():
        return True
    return _auto_generate_persona(persona_name)


def _run_context_update(persona_name: str, user_text: str, mode: str = "llm", debug: bool = False):
    """context_controllerã«çŠ¶æ…‹æ›´æ–°ã ã‘ã‚’ã‚„ã‚‰ã›ã‚‹ï¼ˆstdoutã¯ç„¡è¦–ï¼‰ã€‚
       çµæœã¯stateãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿ç›´ã—ã¦ä½¿ã†ã€‚
    """
    state_file = _state_path_for(persona_name)
    script_path = GAR_ROOT / "style_layer" / "context_controller.py"
    cmd = [
        "python3", os.path.expanduser(script_path),
        "--persona", persona_name,
        "--input_text", user_text,
        "--mode", mode,
        "--state_file", state_file,
    ]
    if debug:
        cmd.append("--debug")

    # emit_text ã¯ã‚µãƒ¼ãƒãƒ¼é‹ç”¨ã§ã¯çµ¶å¯¾ã«ä»˜ã‘ãªã„ï¼ˆstdoutãŒæ··ã–ã‚‹ï¼‰
    proc = subprocess.run(cmd, capture_output=True, text=True)

    if debug and proc.stdout:
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã¨ã—ã¦ã¯æ®‹ã—ã¦OKï¼ˆJSONã§ã¯ãªã„ã®ã§ãƒ‘ãƒ¼ã‚¹ã—ãªã„ï¼‰
        print("[context_controller stdout]", proc.stdout.strip())
    if proc.returncode != 0:
        print("[WARN] context_controller non-zero exit:", proc.stderr.strip())
    return _load_state(persona_name)
    

def _run_style_modulator(persona_name: str, text: str, intensity: float, verbose: bool,
                         relation_axes=None, emotion_axes=None):
    """style_modulatorã‚’å‘¼ã³å‡ºã—ã¦æœ€çµ‚å‡ºåŠ›ã‚’ç”Ÿæˆ"""
    style_script = GAR_ROOT / "style_layer" / "style_modulator.py"
    args = [
        "python3", str(style_script),
        "--persona", persona_name,
        "--text", text,
        "--intensity", str(intensity)
    ]
    if verbose:
        args.append("--verbose")
    if relation_axes:
        args += ["--relation_axes", json.dumps(relation_axes)]
    if emotion_axes:
        args += ["--emotion_axes", json.dumps(emotion_axes)]

    result = subprocess.run(args, capture_output=True, text=True)
    if result.returncode != 0:
        logger.error(f"style_modulator failed:\n{result.stderr}", file=sys.stderr)
        return text

    if "==== Rewritten Text ====" in result.stdout:
        return result.stdout.split("==== Rewritten Text ====")[-1].strip().split("===")[0].strip()
    return result.stdout.strip()

# ============================================================
# FastAPI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ============================================================
@app.get("/health")
async def health():
    return {"status": "ok", "time": time.time()}

# ============================================================
# GAR Command Parser (æ–°ä»•æ§˜å¯¾å¿œ)
# ============================================================

GAR_CMD_RE = re.compile(
    r"[\(\{\[]\s*gar\.(?P<cmd>[a-zA-Z0-9_]+)\s*:(?P<body>[^)\}\]]+)[\)\}\]]"
)

def extract_gar_commands(text: str):
    """æ–‡ä¸­ã‹ã‚‰ gar ã‚³ãƒãƒ³ãƒ‰ã‚’ã™ã¹ã¦æŠ½å‡º"""
    matches = GAR_CMD_RE.finditer(text or "")
    commands = []
    for m in matches:
        cmd = m.group("cmd").strip()
        body = m.group("body").strip()
        commands.append({"cmd": cmd, "body": body})
    return commands

def strip_gar_commands(text: str) -> str:
    """garã‚³ãƒãƒ³ãƒ‰ã‚’æœ¬æ–‡ã‹ã‚‰é™¤å»ã—ã¤ã¤ã€personaåã¯æ®‹ã™"""
    def replacer(match):
        cmd = match.group("cmd").strip()
        body = match.group("body").strip().split(";")[0]
        # personaã‚³ãƒãƒ³ãƒ‰ã®å ´åˆã¯åå‰ã‚’æ®‹ã™
        if cmd == "persona":
            return body
        # ãã‚Œä»¥å¤–ã¯å®Œå…¨é™¤å»
        return ""
    return GAR_CMD_RE.sub(replacer, text or "").strip()

def clean_messages(messages):
    # ã‚³ãƒãƒ³ãƒ‰æ§‹æ–‡ã‚’å‰Šé™¤ã—ã€å…¨å±¥æ­´ã‚’ã¾ã¨ã‚ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ cleaned_text ã«æ ¼ç´
    joined_messages = []
    for m in messages:
        role = m.get("role", "").upper()
        content = strip_gar_commands(m.get("content", ""))
        joined_messages.append(f"{role}: {content}")
    cleaned_text = "\n".join(joined_messages)
    return cleaned_text


def extract_persona_from_messages(messages):
    """(gar.persona: â€¦) æ§‹æ–‡ã‹ã‚‰æœ€å¾Œã«æŒ‡å®šã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠåã‚’æŠ½å‡º"""
    for m in reversed(messages):
        if m.get("role") != "user":
            continue
        text = m.get("content", "")
        commands = extract_gar_commands(text)
        persona_cmds = [c for c in commands if c["cmd"] == "persona"]
        if persona_cmds:
            persona = persona_cmds[-1]["body"].split(";")[0].strip()
            return persona
    return None


def inject_system_message(messages: list[dict], content: str):
    """
    chatå±¥æ­´ã« system ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ­£ã—ã„å½¢å¼ã§æŒ¿å…¥ã™ã‚‹ã€‚
    é€šå¸¸ã¯æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç›´å¾Œã«è¿½åŠ ã•ã‚Œã‚‹ã€‚
    """
    # æŒ¿å…¥ä½ç½®ï¼šæœ€å¾Œã® user ã®ç›´å¾Œ
    insert_index = len(messages)
    for i in reversed(range(len(messages))):
        if messages[i].get("role") == "user":
            insert_index = i + 1
            break

    system_entry = {"role": "system", "content": content}
    messages.insert(insert_index, system_entry)
    return messages
    

def get_last_message(messages):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‹ã‚‰æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡ã‚’å–å¾—"""
    last_message = next((m for m in reversed(messages) if m.get("role") == "user"), None)
    text = last_message.get("content", "") if last_message else ""
    return text


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    req = await request.json()
    messages = req.get("messages", [])
    if not messages:
        return JSONResponse(status_code=400, content={"error": "messages is required"})

    # logger.debug(f"Received /v1/chat/completions request\n{req}")

    cleaned_text = clean_messages(messages)
    last_message = get_last_message(messages)
    intensity = float(req.get("intensity", 0.8))
    verbose = bool(req.get("verbose", False))

    # --- OpenWebUIã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚„ã‚¿ã‚¤ãƒˆãƒ«ãªã©å†…éƒ¨ãƒ¡ã‚¿ã‚¿ã‚¹ã‚¯ã‚’æ¤œçŸ¥ã—ãŸå ´åˆã¯ã€LLMã¸ç›´æ¥ãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ ---
    if _is_internal_prompt(last_message):
        #logger.debug("Internal meta task detected â€” skipping response_modulator and passing through.")
        # LLMã¸ç›´æ¥ãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼
        raw_response = request_llm(
            messages=messages,  # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã¾ã¾
            backend="auto",
            temperature=0.7,
            max_tokens=800,
        )
        return JSONResponse(
            content={
                "id": f"chatcmpl-{os.urandom(8).hex()}",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": "gar-llm",
                "choices": [{
                    "index": 0,
                    "message": {"role": "assistant", "content": raw_response},
                    "finish_reason": "stop"
                }],
                "usage": {"prompt_tokens": None, "completion_tokens": None, "total_tokens": None}
            }
        )


    # persona æŒ‡å®šã‚’æ¤œå‡ºã™ã‚‹
    persona_name = (
        req.get("persona")
        or extract_persona_from_messages(messages)
        or args.persona
        or "default"
    )

    # gar.persona ãŒæ–°ãŸã«æŒ‡å®šã•ã‚Œã¦ã„ãŸå ´åˆã®ã¿åˆ‡ã‚Šæ›¿ãˆé€šçŸ¥
    commands = extract_gar_commands(last_message)
    persona_cmds = [c for c in commands if c["cmd"] == "persona"]

    if persona_cmds and args.inject_system == "on":
        already_injected = any(
            m.get("role") == "system" and persona_name in m.get("content", "")
            for m in messages
        )

        if not already_injected:
            switch_text = f"assistantã¯ã“ã“ã‹ã‚‰ {persona_name} ã®äººæ ¼ã¨ã—ã¦å¿œç­”ã—ã¦ã„ã¾ã™ã€‚"
            logger.info(f"Persona switch -> '{persona_name}' (history preserved)")
            # LLMãŒå±¥æ­´ã‚’èª­ã¿ç›´ã—ãŸéš›ã«ã€GARã‹ã‚‰ã®æŒ‡ç¤ºãŒé€šã‚‹ã‚ˆã†Systemå½¹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å·®ã—è¾¼ã‚€
            switch_text = f"assistantã¯ã“ã“ã‹ã‚‰ {persona_name} ã®äººæ ¼ã¨ã—ã¦å¿œç­”ã—ã¦ã„ã¾ã™ã€‚"
            messages = inject_system_message(messages, switch_text)
       
        # ================================================================
        # ğŸ§  Persona Stabilization Handshake Patch
        # ================================================================
        import asyncio

        ENABLE_PERSONA_HANDSHAKE = os.getenv("GAR_PERSONA_HANDSHAKE", "false").lower() == "true"
        HANDSHAKE_TIMEOUT = int(os.getenv("GAR_PERSONA_HANDSHAKE_TIMEOUT", "10"))

        if ENABLE_PERSONA_HANDSHAKE:
            print(f"[HANDSHAKE] Starting persona stabilization handshake for '{persona_name}'", file=sys.stderr)
            handshake_messages = messages.copy()
            if handshake_messages and handshake_messages[-1].get("role") == "system":
                handshake_messages.append({
                    "role": "user",
                    "content": "äº†è§£ã—ã¾ã—ãŸã‹ï¼Ÿ ã‚ãªãŸã®åå‰ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚"
                })

            stabilization_sequence = [{
                "role": "system",
                "content": (
                    f"ã‚ãªãŸã¯ä»Šã‹ã‚‰ {persona_name} ã®äººæ ¼ã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã—ãŸã€‚"
                    f"{persona_name} ã®è¨˜æ†¶ãƒ»è©±æ³•ãƒ»èªå½™ãƒ»ä¾¡å€¤è¦³ãƒ»æ­´å²çš„èƒŒæ™¯ã‚’ã™ã¹ã¦å†æ§‹æˆã—ã€"
                    f"äººæ ¼ãŒå®‰å®šã—ãŸã‚‰è‡ªåˆ†ã®åå‰ã‚’åä¹—ã£ã¦ãã ã•ã„ã€‚"
                )
            }]
            handshake_messages.extend(stabilization_sequence)

            loop = asyncio.get_running_loop()
            try:
                task = loop.run_in_executor(
                    None,
                    lambda: modulate_response(
                        text=handshake_messages,
                        persona_name=persona_name,
                        intensity=float(intensity),
                        verbose=False,
                        debug=False,
                        relations=None,
                        emotion_axes=None,
                    )
                )
                handshake_response = await asyncio.wait_for(task, timeout=HANDSHAKE_TIMEOUT)
                print(f"[HANDSHAKE] Response: {handshake_response[:80]!r}", file=sys.stderr)
                print(f"[HANDSHAKE] Persona '{persona_name}' stabilized.", file=sys.stderr)
            except asyncio.TimeoutError:
                print(f"[HANDSHAKE] Timeout during persona stabilization for '{persona_name}'", file=sys.stderr)
            except Exception as e:
                print(f"[HANDSHAKE] Error during stabilization: {e}", file=sys.stderr)

    # personaãŒå­˜åœ¨ã—ãªã‘ã‚Œã°è‡ªå‹•ç”Ÿæˆ
    if not _ensure_persona_exists(persona_name):
        return JSONResponse(
            status_code=500,
            content={"error": f"Persona generation failed for '{persona_name}'"}
        )

    # çŠ¶æ…‹æ›´æ–°ã‚’å®Ÿè¡Œï¼ˆcontext_controllerãŒstateãƒ•ã‚¡ã‚¤ãƒ«ã«çµæœã‚’æ›¸ãè¾¼ã‚€ï¼‰
    # _run_context_update(persona_name, cleaned_text, mode="llm", debug=args.debug)
    context_input = json.dumps(messages, ensure_ascii=False)
    _run_context_update(persona_name, context_input, mode="llm", debug=args.debug)


    # æ›´æ–°å¾Œã®stateã‚’èª­ã¿å‡ºã™
    context_data = _load_state(persona_name)
    relations = context_data.get("relations", {})
    emotion_axes = context_data.get("emotion_axes", {})

    # ğŸ’¬ LLMã«ãƒªãƒ¬ãƒ¼ã™ã‚‹messageså…¨ä½“ã‚’ç¢ºèª
    logger.debug("Messages before response modulation:\n" + json.dumps(messages, ensure_ascii=False, indent=2))

    rewritten = modulate_response(
        text=messages,
        persona_name=persona_name,
        intensity=intensity,
        verbose=verbose,
        debug=args.debug,
        relations=relations,
        emotion_axes=emotion_axes
    )

    keep_one = (args.prefix_persona == "on") and (persona_name and persona_name != "default")
    rewritten = _normalize_persona_prefix(rewritten, persona_name, keep_one)

    response = {
        "id": f"chatcmpl-{os.urandom(8).hex()}",
        "object": "chat.completion",
        "created": int(time.time()),
        "model": "gar-llm",
        "choices": [{
            "index": 0,
            "message": {"role": "assistant", "content": rewritten},
            "finish_reason": "stop"
        }],
        "usage": {"prompt_tokens": None, "completion_tokens": None, "total_tokens": None}
    }
    return JSONResponse(content=response)

# ============================================================
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ============================================================
if __name__ == "__main__":
    import argparse
    import uvicorn

    parser = argparse.ArgumentParser(description="GAR-LLM Relay Server")
    parser.add_argument("--host", type=str, default="0.0.0.0")
    parser.add_argument("--port", type=int, default=8081)
    parser.add_argument("--persona", type=str, default="default", help="(ä»»æ„) ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ«ã‚½ãƒŠåã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã« persona ãŒãªã„å ´åˆã«ä½¿ç”¨ã€‚")
    parser.add_argument("--handshake", choices=["on", "off", "auto"],
                        default=os.getenv("GAR_HANDSHAKE", "off"),
                        help="ãƒšãƒ«ã‚½ãƒŠåˆ‡æ›¿æ™‚ã®åä¹—ã‚Šãƒãƒ³ãƒ‰ã‚·ã‚§ã‚¤ã‚¯ï¼ˆon/off/autoï¼‰")
    parser.add_argument("--inject-system", choices=["on", "off"], default=os.getenv("GAR_INJECT_SYSTEM", "on"))
    parser.add_argument("--prefix-persona", choices=["on", "off"], default=os.getenv("GAR_PREFIX_PERSONA", "on"))
    parser.add_argument("--debug", action="store_true", help="ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–ï¼ˆ--log-console ä½µç”¨å¯ï¼‰")
    parser.add_argument("--log-console", action="store_true", help="ãƒ­ã‚°ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›")

    args = parser.parse_args()

    # ============================================================
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«åˆ¶å¾¡ï¼ˆ--debug ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å”¯ä¸€ã®ãƒˆãƒªã‚¬ã«ï¼‰
    # ============================================================
    log_level = "DEBUG" if args.debug else "INFO"
    logger = get_logger("relay_server", level=log_level, to_console=args.log_console)

    logger.info(f"Starting Ghost Assimilation Relay Server on {args.host}:{args.port} (log_level={log_level})")

    uvicorn.run(app, host=args.host, port=args.port)
