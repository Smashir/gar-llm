#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
response_modulator.py â€” Persona Response Layer with Relation + Emotion Axes

ç›®çš„:
  - å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ= ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ï¼‰ã«å¯¾ã—ã¦ã€
    ã€Œãƒšãƒ«ã‚½ãƒŠï¼ˆpersona_*.jsonï¼‰ã€ã¨ã€ŒçŠ¶æ…‹ï¼ˆrelation_axes / emotion_axesï¼‰ã€ã‚’åæ˜ ã—ãŸ
    å¿œç­”æ–‡ï¼ˆassistantç™ºè©±ï¼‰ã‚’ **ç›´æ¥ç”Ÿæˆ** ã™ã‚‹ã€‚

é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼ˆæœ€å°å¤‰æ›´æ–¹é‡ï¼‰:
  - æ—¢å­˜ style_modulator ã¨åŒã˜ CLI/é–¢æ•°ã‚·ã‚°ãƒãƒãƒ£ã‚’ç¶­æŒ
    * def modulate_style(text, persona_name, intensity, verbose, debug, relation_axes, emotion_axes)
    * --persona / --text / --intensity / --verbose / --relation_axes / --emotion_axes
  - å†…éƒ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’ã€Œè¨€ã„æ›ãˆã€â†’ã€Œå¿œç­”æ–‡ç”Ÿæˆã€ã«å¤‰æ›´
  - relation_axes: Respect ã‚’æ­£å¼å¯¾å¿œï¼ˆPower ã‚‚å¾Œæ–¹äº’æ›ï¼‰
  - LLM å‡ºåŠ›ã®å¾Œå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—ï¼ˆ--- åŒºåˆ‡ã‚Šã®é™¤å»ãªã©ï¼‰
"""

import os
import json
import argparse
from pathlib import Path
from typing import Dict, Any
import re
import sys
import time
import hashlib


# sys.path.append(os.path.expanduser("~/modules/gar-llm/src/"))

from garllm.utils.llm_client import request_llm
from garllm.utils.env_utils import get_data_path
from garllm.utils.logger import get_logger

# ==========================================
# Utility
# ==========================================

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = get_logger("response_modulator", level="INFO", to_console=False)


_STYLE_PROFILE_STATS = {"hit": 0, "miss": 0}

# ============================================================
# âš¡ Speed-up caches (in-process)
# ============================================================
_PERSONA_CACHE: dict[str, dict] = {}
_STYLE_PROFILE_CACHE: dict[str, dict[str, object]] = {}  # key -> {"profile": str, "ts": float}
# style_profile cache GC (TTL + max entries)
def _gc_style_profile_cache(ttl_sec: float, max_entries: int) -> int:
    """
    TTLè¶…éã‚’å‰Šé™¤ã—ã€max_entriesã‚’è¶…ãˆãŸã‚‰å¤ã„é †ã«å‰Šé™¤ã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: å‰Šé™¤ã—ãŸä»¶æ•°
    """
    if ttl_sec <= 0 and (max_entries is None or max_entries <= 0):
        return 0

    now = time.time()
    removed = 0

    # 1) TTLè¶…éã‚’å‰Šé™¤
    if ttl_sec > 0:
        expired = []
        for k, ent in _STYLE_PROFILE_CACHE.items():
            try:
                ts = float(ent.get("ts", 0.0))
            except Exception:
                ts = 0.0
            if (now - ts) > ttl_sec:
                expired.append(k)

        for k in expired:
            if _STYLE_PROFILE_CACHE.pop(k, None) is not None:
                removed += 1

    # 2) max_entriesè¶…éã‚’å‰Šé™¤ï¼ˆå¤ã„é †ï¼‰
    if max_entries is not None and max_entries > 0:
        over = len(_STYLE_PROFILE_CACHE) - max_entries
        if over > 0:
            items = sorted(
                _STYLE_PROFILE_CACHE.items(),
                key=lambda kv: float((kv[1] or {}).get("ts", 0.0)),
            )
            for i in range(over):
                k = items[i][0]
                if _STYLE_PROFILE_CACHE.pop(k, None) is not None:
                    removed += 1

    return removed


def _quantize_axes(axes: dict[str, float] | None, step: float = 0.25) -> dict[str, float]:
    """
    å°ã•ãªæºã‚Œã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒç„¡åŠ¹åŒ–ã•ã‚Œãªã„ã‚ˆã†ã€è»¸å€¤ã‚’ç²—ãä¸¸ã‚ã‚‹ã€‚
    step=0.25 ãªã‚‰ -1..1 ã‚’ 0.25åˆ»ã¿ã€‚
    """
    if not axes:
        return {}
    q: dict[str, float] = {}
    for k, v in axes.items():
        try:
            fv = float(v)
        except Exception:
            continue
        fv = max(-1.0, min(1.0, fv))
        q[k] = round(fv / step) * step
    return q


def _quantize_phase_weights(
    phase_weights: dict[str, float] | None,
    *,
    step: float = 0.25,
    scale_by_n: bool = True,
) -> list[tuple[str, float]]:
    """
    phase_weights(ç·å’Œ=1) ã‚’ã€Œå…¨ç›¸ãƒ»å›ºå®šé †ã€ã§é‡å­åŒ–ã—ã¦ç½²åã«ã™ã‚‹ã€‚

    - å…¨ç›¸ã‚’æ‰ãˆã‚‹ï¼ˆTop-Kã«ã—ãªã„ï¼‰ã®ã§ã€A/Bé€†è»¢ãªã©ã‚‚ç¢ºå®Ÿã«æ¤œå‡ºã§ãã‚‹
    - Nç›¸ã®é•ã„ã‚’å¸åã—ãŸã„å ´åˆã¯ scale_by_n=True ã«ã—ã¦ w*N ã‚’é‡å­åŒ–ã™ã‚‹
    - å‡ºåŠ›ã¯ [(phase_name, bucket), ...] ã®å®‰å®šãªãƒªã‚¹ãƒˆï¼ˆnameé †ï¼‰
    """
    if not phase_weights:
        return []

    # å®‰å®šé †ï¼ˆè¾æ›¸é †ã®æºã‚Œã‚’é¿ã‘ã‚‹ï¼‰
    names = sorted([k for k in phase_weights.keys() if isinstance(k, str)])
    n = len(names) if names else 0
    if n <= 0:
        return []

    sig: list[tuple[str, float]] = []
    for name in names:
        v = phase_weights.get(name, 0.0)
        try:
            w = float(v)
        except Exception:
            w = 0.0
        w = max(0.0, min(1.0, w))

        x = (w * n) if scale_by_n else w
        # é‡å­åŒ–
        b = round(x / step) * step
        sig.append((name, round(float(b), 4)))

    return sig


def _style_profile_cache_key(
    persona_name: str,
    phase_weights: dict[str, float] | None,
    relation_axes: dict[str, float] | None,
    emotion_axes: dict[str, float] | None,
    intensity: float,
    *,
    step_axes: float = 0.25,
    step_phase: float = 0.25,
    scale_phase_by_n: bool = True,
) -> str:
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ï¼špersona + é‡å­åŒ–ã—ãŸ phase_weights + é‡å­åŒ–ã—ãŸé–¢ä¿‚/æ„Ÿæƒ… + intensity(ç²—ã)

    phase_fusion(description/refs) ã¯ã€Œæ–‡å­—åˆ—ãƒ»é †åºã€ãŒæºã‚Œã‚„ã™ã„ã®ã§ã‚­ãƒ¼ã‹ã‚‰å¤–ã™ã€‚
    """
    payload = {
        "persona": persona_name,
        "phase": _quantize_phase_weights(
            phase_weights,
            step=step_phase,
            scale_by_n=scale_phase_by_n,
        ),
        "rel": _quantize_axes(relation_axes, step=step_axes),
        "emo": _quantize_axes(emotion_axes, step=step_axes),
        "int": round(float(intensity), 2),
    }
    raw = json.dumps(payload, ensure_ascii=False, sort_keys=True).encode("utf-8")
    return hashlib.sha1(raw).hexdigest()


def load_persona_profile_cached(persona_name: str) -> Dict[str, Any]:
    """
    æ—¢å­˜ load_persona_profile ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç‰ˆï¼ˆåŒä¸€ãƒ—ãƒ­ã‚»ã‚¹å†…ï¼‰
    """
    if persona_name in _PERSONA_CACHE:
        return _PERSONA_CACHE[persona_name]
    data = load_persona_profile(persona_name)
    _PERSONA_CACHE[persona_name] = data
    return data


# ============================================================
# ğŸ“‚ Persona Profile Loader
# ============================================================
def load_persona_profile(persona_name: str) -> Dict[str, Any]:
    """
    ãƒšãƒ«ã‚½ãƒŠå®šç¾©JSONã®ãƒ­ãƒ¼ãƒ‰:
      data/personas/persona_<name>.json ã‚’èª­ã‚€
    """
    base_dir = Path(get_data_path("personas"))
    persona_path = base_dir / f"persona_{persona_name}.json"
    with open(persona_path, "r", encoding="utf-8") as f:
        persona_data = json.load(f)

    # expression_bank ãŒå¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯çµ±åˆ
    expr_path = base_dir / f"expression_{persona_name}.json"
    if expr_path.exists():
        with open(expr_path, "r", encoding="utf-8") as f:
            persona_data["expression_bank"] = json.load(f)
    return persona_data

# ============================================================
# ğŸ­ Expression Injectorï¼ˆè¡¨ç¾è¾æ›¸çµ±åˆãƒ¬ã‚¤ãƒ¤ï¼‰
# ============================================================
import random

def _collect_expression_refs(persona_data: dict, phase_name: str | None):
    """
    persona_data["expression_bank"] ã¨ phase æƒ…å ±ã‹ã‚‰ã€
    åˆ©ç”¨å¯¾è±¡ã¨ãªã‚‹ (category, key) ã®çµ„ã‚’é›†ç´„ã™ã‚‹ã€‚
    - phase.expression_refs ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ "cat.key"
    - phase.description å†…ã«æ›¸ã‹ã‚ŒãŸ "cat.key"
    """
    bank = persona_data.get("expression_bank") or {}
    refs: set[tuple[str, str]] = set()

    if not bank or not phase_name:
        return bank, refs

    phases = persona_data.get("phases") or {}
    phase = phases.get(phase_name) or {}

    # 1) æ˜ç¤ºçš„ãª expression_refs
    for ref in phase.get("expression_refs", []):
        if not isinstance(ref, str):
            continue
        if "." not in ref:
            continue
        cat, key = ref.split(".", 1)
        sub = bank.get(cat)
        if isinstance(sub, dict) and key in sub:
            refs.add((cat, key))

    # 2) description å†…ã® "cat.key"
    desc = phase.get("description", "")
    if isinstance(desc, str) and desc:
        found = re.findall(r"([a-zA-Z0-9_]+)\.([a-zA-Z0-9_]+)", desc)
        for cat, key in found:
            sub = bank.get(cat)
            if isinstance(sub, dict) and key in sub:
                refs.add((cat, key))

    return bank, refs


def extract_expression_snippets(persona_data: dict, phase_name: str | None = None) -> str:
    """
    persona_data["expression_bank"] ã‚’èª­ã¿è¾¼ã¿ã€
    å¯¾è±¡ phase ã§åˆ©ç”¨ã•ã‚Œã‚‹ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    - phase_name ãŒã‚ã‚Œã°ã€ãã® phase ã«é–¢é€£ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æŠ½å‡º
    - ãã‚Œã‚‚ç„¡ã‘ã‚Œã° expression_bank å…¨ä½“ã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    bank, refs = _collect_expression_refs(persona_data, phase_name)
    if not bank:
        return ""

    samples: list[str] = []

    if refs:
        # æŒ‡å®šã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æŠ½å‡º
        for (cat, key) in refs:
            sub = bank.get(cat, {})
            if isinstance(sub, dict):
                lst = sub.get(key)
                if isinstance(lst, list) and lst:
                    samples.append(random.choice(lst))
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…¨ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡º
        flat: list[str] = []
        for cat, sub in bank.items():
            if isinstance(sub, dict):
                for key, lst in sub.items():
                    if isinstance(lst, list):
                        flat.extend(lst)
        if flat:
            samples.append(random.choice(flat))

    if not samples:
        return ""

    joined = " / ".join(samples[:3])
    return f"ã€è¡¨ç¾ãƒ’ãƒ³ãƒˆã‚µãƒ³ãƒ—ãƒ«ã€‘{joined}"


def sample_expression_snippets_weighted(
    persona_data: dict,
    expression_refs: list[str] | None,
    max_samples: int = 3,
) -> list[str]:
    """
    ãƒ•ã‚§ãƒ¼ã‚ºé‡ç•³ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸ expression_refs ã«åŸºã¥ãã€
    expression_<persona>.json ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½é¸ã™ã‚‹ã€‚

    å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³:
      - "talk.intro" ã®ã‚ˆã†ãª cat.key å½¢å¼
      - "battle_cries" ã®ã‚ˆã†ãªãƒ‰ãƒƒãƒˆç„¡ã—ã‚­ãƒ¼ï¼ˆexpression_bank[ref]ï¼‰

    ãƒ»expression_refs ãŒ None or ç©ºãªã‚‰å¾“æ¥ã® extract_expression_snippets() ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    ãƒ»ã‚«ãƒ†ã‚´ãƒªå†…ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã¯ expression ã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã›ãšã€"ç´ æ" ã¨ã—ã¦ãã®ã¾ã¾æ¸¡ã™ã€‚
      ï¼ˆæºã‚‰ãã¥ã‘ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆç”¨LLMãŒæ‹…å½“ï¼‰
    """
    expressions = persona_data.get("expression_bank") or {}
    if not expressions:
        return []

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: refs ãŒç„¡ã„å ´åˆã¯æ—§ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ä½¿ã†
    if not expression_refs:
        try:
            snippet = extract_expression_snippets(persona_data, phase_name=None)
        except Exception:
            snippet = ""
        return [snippet] if snippet else []

    flat_list: list[str] = []

    for ref in expression_refs:
        if not isinstance(ref, str):
            continue

        # 1) "cat.key" å½¢å¼
        if "." in ref:
            cat, key = ref.split(".", 1)
            sub = expressions.get(cat)
            if isinstance(sub, dict):
                arr = sub.get(key)
                if isinstance(arr, list):
                    for item in arr:
                        if isinstance(item, str):
                            flat_list.append(item)
            continue

        # 2) ãƒ‰ãƒƒãƒˆç„¡ã—ã‚­ãƒ¼ â†’ expression_bank[ref] ã‚’è¦‹ã‚‹
        val = expressions.get(ref)
        if isinstance(val, list):
            for item in val:
                if isinstance(item, str):
                    flat_list.append(item)
        elif isinstance(val, dict):
            # ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’ã™ã¹ã¦ãƒ•ãƒ©ãƒƒãƒˆã«é›†ç´„
            for lst in val.values():
                if isinstance(lst, list):
                    for item in lst:
                        if isinstance(item, str):
                            flat_list.append(item)

    if not flat_list:
        return []

    random.shuffle(flat_list)
    return flat_list[:max_samples]



def build_expression_instruction(
    persona_data: dict,
    phase_name: str | None = None,
    expression_refs: list[str] | None = None,
) -> str:
    """
    ç›¸ã«ç´ã¥ã expression ã®ä½¿ã„æ–¹ã‚’ã€LLM å‘ã‘ã®ã€Œæ“ä½œãƒ«ãƒ¼ãƒ«ã€ã¨ã—ã¦æ–‡ç« åŒ–ã™ã‚‹ã€‚

    å¯¾å¿œãƒ‘ã‚¿ãƒ¼ãƒ³:
      - "cat.key" å½¢å¼ï¼ˆä¾‹: "talk.intro"ï¼‰
      - "flat_key" å½¢å¼ï¼ˆä¾‹: "battle_cries"ï¼‰
    """
    bank = persona_data.get("expression_bank") or {}
    if not bank:
        return ""

    pair_refs: set[tuple[str, str]] = set()  # ("cat","key")
    flat_keys: set[str] = set()              # "battle_cries" ãªã©

    # 1) phase_name ãƒ™ãƒ¼ã‚¹ã®å‚ç…§ï¼ˆå¾“æ¥ã®æŒ™å‹• + flat key æ‹¡å¼µï¼‰
    if phase_name is not None:
        try:
            _, phase_pairs = _collect_expression_refs(persona_data, phase_name)
            pair_refs.update(phase_pairs)
        except Exception:
            pass

        phases = persona_data.get("phases") or {}
        phase = phases.get(phase_name) or {}
        for ref in phase.get("expression_refs", []):
            if not isinstance(ref, str):
                continue
            if "." in ref:
                cat, key = ref.split(".", 1)
                pair_refs.add((cat, key))
            else:
                flat_keys.add(ref)

    # 2) phase_fusion ãªã©ã‹ã‚‰æ¸¡ã•ã‚ŒãŸ expression_refs
    if expression_refs:
        for ref in expression_refs:
            if not isinstance(ref, str):
                continue
            if "." in ref:
                cat, key = ref.split(".", 1)
                pair_refs.add((cat, key))
            else:
                flat_keys.add(ref)

    # å®Ÿåœ¨ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã ã‘ã«çµã‚Šè¾¼ã‚€
    valid_pairs: set[tuple[str, str]] = set()
    for cat, key in pair_refs:
        sub = bank.get(cat)
        if isinstance(sub, dict) and key in sub:
            valid_pairs.add((cat, key))
    pair_refs = valid_pairs

    valid_flat: set[str] = set()
    for k in flat_keys:
        val = bank.get(k)
        if isinstance(val, (list, dict)):
            valid_flat.add(k)
    flat_keys = valid_flat

    if not pair_refs and not flat_keys:
        return ""

    persona_label = persona_data.get("persona_name") or "ãƒšãƒ«ã‚½ãƒŠ"
    lines: list[str] = []
    lines.append("ã€ç›¸ã«åŸºã¥ãè¡¨ç¾æ“ä½œãƒ«ãƒ¼ãƒ«ã€‘")
    lines.append("ãƒ»ä»¥ä¸‹ã® expression ã‚«ãƒ†ã‚´ãƒªã¯ã€å…ƒã®æ–‡ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒšã™ã‚‹ã®ã§ã¯ãªãã€æ„å‘³ã¨ãƒãƒªã‚’ä¿ã¡ãªãŒã‚‰ã€é¡ç¾©èªãƒ»è¨€ã„æ›ãˆãƒ»èªå°¾å¤‰å½¢ãƒ»ã‚«ã‚¿ã‚«ãƒŠåŒ–ãƒ»å³èˆˆé€ èªãªã©ã§å†æ§‹æˆã—ã¦ã‚ˆã„ã€‚")
    lines.append("ãƒ»ã‚«ãƒ†ã‚´ãƒªå†…ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã¯ã€Œç´ æã€ã¨ã—ã¦æ‰±ã„ã€è¤‡æ•°ã‚’çµ„ã¿åˆã‚ã›ãŸã‚Šéƒ¨åˆ†çš„ã«å¤‰å½¢ã—ã¦ã€æ–°ã—ã„ã‚»ãƒªãƒ•ã‚„æ­Œè©ã‚’ä½œã‚‹ã“ã¨ã€‚")
    lines.append("ãƒ»ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ã„ãã¤ã‹ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç¤ºã™ãŒã€ãã®ã¾ã¾å›ºå®šæ–‡ã¨ã—ã¦ã§ã¯ãªãã€å¿…ãšå°‘ã—æºã‚‰ãã‚’åŠ ãˆã¦ä½¿ã†ã“ã¨ã€‚")

    # ã¾ãš cat.key å½¢å¼
    for cat, key in sorted(pair_refs):
        lines.append(f"ãƒ»{cat}.{key} : expression_{persona_label}.json å†…ã®ãƒ•ãƒ¬ãƒ¼ã‚ºç¾¤ã‚’ç´ æã¨ã—ã¦åˆ©ç”¨ã›ã‚ˆã€‚")
        sub = bank.get(cat, {})
        if not isinstance(sub, dict):
            continue
        lst = sub.get(key)
        if not isinstance(lst, list) or not lst:
            continue

        examples = [s for s in lst if isinstance(s, str) and s.strip()]
        random.shuffle(examples)
        for ex in examples[:2]:
            ex_clean = ex.strip()
            lines.append(
                f"    - ä¾‹(cat.{key}): ã€Œ{ex_clean}ã€ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’ä¿ã¡ã¤ã¤ã€èªå°¾ã‚„è¨€ã„å›ã—ã‚’å°‘ã—å¤‰å½¢ã—ã¦ä½¿ã£ã¦ã‚ˆã„ã€‚"
            )

    # æ¬¡ã« flat key å½¢å¼
    for k in sorted(flat_keys):
        lines.append(f"ãƒ»{k} : expression_{persona_label}.json å†…ã®ãƒ•ãƒ¬ãƒ¼ã‚ºç¾¤ã‚’ç´ æã¨ã—ã¦åˆ©ç”¨ã›ã‚ˆã€‚")
        val = bank.get(k)
        flat: list[str] = []
        if isinstance(val, list):
            flat.extend(s for s in val if isinstance(s, str) and s.strip())
        elif isinstance(val, dict):
            for lst in val.values():
                if isinstance(lst, list):
                    flat.extend(s for s in lst if isinstance(s, str) and s.strip())

        if not flat:
            continue

        random.shuffle(flat)
        for ex in flat[:2]:
            ex_clean = ex.strip()
            lines.append(
                f"    - ä¾‹({k}): ã€Œ{ex_clean}ã€ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’ä¿ã¡ã¤ã¤ã€èªå°¾ã‚„è¨€ã„å›ã—ã‚’å°‘ã—å¤‰å½¢ã—ã¦ä½¿ã£ã¦ã‚ˆã„ã€‚"
            )

    return "\n".join(lines)





def build_pronoun_guidance(persona_data: Dict[str, Any], relations: Dict[str, Dict[str, float]] | None) -> str:
    """å€™è£œãƒªã‚¹ãƒˆã‚’ãã®ã¾ã¾æç¤ºã—ã€å€™è£œå¤–ã®ä½¿ç”¨ç¦æ­¢ã¨é¸æŠè¦å‰‡ã‚’æ˜è¨˜ã™ã‚‹ã€‚"""
    style = persona_data.get("style", {})
    fp_list = style.get("first_person", []) or ["ç§"]
    sp_list = style.get("second_person", []) or ["ã‚ãªãŸ"]

    # é–¢ä¿‚æ€§ã‚’è¦‹ã¦ LLM ã«é¸ã°ã›ã‚‹ï¼ˆãƒ«ãƒ¼ãƒ«æ˜è¨˜ï¼‰
    relation_hint = "é–¢ä¿‚æ€§ã«å¿œã˜ã¦è‡ªç„¶ã«é¸æŠã™ã‚‹ã“ã¨ã€‚è¦ªå¯†åº¦ãŒé«˜ã„ã»ã©ç •ã‘ãŸå€™è£œã€ä½ã„ã»ã©ä¸å¯§ãªå€™è£œã‚’é¸ã¶ã“ã¨ã€‚"
    # å€™è£œå¤–ç¦æ­¢ãƒ»ã€Œä½™/æˆ‘/æ‹™è€…ã€ç­‰ã®å‹æ‰‹ãªå¤‰æ›æŠ‘æ­¢
    hard_rules = (
        "ä¸€äººç§°ã¨äºŒäººç§°ã¯å¿…ãšä¸‹è¨˜å€™è£œã‹ã‚‰é¸ã¶ã“ã¨ã€‚å€™è£œã«ç„¡ã„äººç§°ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã€‚"
        " æ—¢å­˜å±¥æ­´ã®å£èª¿ã«å¼•ããšã‚‰ã‚Œãªã„ã“ã¨ã€‚"
    )
    return (
        f"ä¸€äººç§°å€™è£œ: {', '.join(fp_list)} / "
        f"äºŒäººç§°å€™è£œ: {', '.join(sp_list)}ã€‚"
        f" {relation_hint} {hard_rules}"
    )


# ============================================================
# ğŸ” Axis Hintsï¼ˆé–¢ä¿‚æ€§/æ„Ÿæƒ…ã‚’è‡ªç„¶è¨€èªã®æŒ‡é‡ã«ï¼‰
# ============================================================
AXIS_DESCRIPTIONS = {
    "Trust": ("å®‰å¿ƒæ„Ÿãƒ»è‚¯å®šãƒ»å¯›å®¹ã«è©±ã™", "æ…é‡ãƒ»ç–‘å¿µã‚’æŒã¡è·é›¢ã‚’å–ã‚‹"),
    "Familiarity": ("ç •ã‘ãŸãƒ»è»½å£ãƒ»è¦ªå¯†ã«è©±ã™", "ä¸å¯§ãƒ»èª¬æ˜çš„ãƒ»å½¢å¼çš„ã«è©±ã™"),
    "Hostility": ("æ”»æ’ƒçš„ãƒ»æŒ‘ç™ºçš„ãƒ»æ‰¹åˆ¤çš„ã«è©±ã™", "ç©ã‚„ã‹ãƒ»æŸ”ã‚‰ã‹ããƒ»è­²æ­©çš„ã«è©±ã™"),
    "Dominance": ("ä¸»å°çš„ãƒ»å‘½ä»¤çš„ãƒ»æ–­å®šçš„ã«è©±ã™", "å¾“å±çš„ãƒ»å—å®¹çš„ãƒ»å‚¾è´çš„ã«è©±ã™"),
    "Empathy": ("æ„Ÿæƒ…ã‚’æ‹¾ã„ãƒ»å…±æ„Ÿã‚’ç¤ºã™", "å†·é™ãƒ»å®¢è¦³çš„ãƒ»æ„Ÿæƒ…ã‚’çœã"),
    "Instrumentality": ("åŠ¹ç‡é‡è¦–ãƒ»å–å¼•çš„ã«è©±ã™", "ç„¡å„Ÿãƒ»æ„Ÿæƒ…çš„ãƒ»ç´”ç²‹ã«è©±ã™")
}

def describe_axis(name: str, value: float) -> str:
    """Relationè»¸ã‚’é€£ç¶šãƒˆãƒ¼ãƒ³ã§è¨˜è¿°ï¼ˆå¼·åº¦=çµ¶å¯¾å€¤ã€ç¬¦å·ã§æ–¹å‘é¸æŠï¼‰"""
    pos_text, neg_text = AXIS_DESCRIPTIONS.get(name, ("æ­£æ–¹å‘", "è² æ–¹å‘"))
    strength = abs(value)
    if strength < 0.05:
        return f"{name}: ä¸­ç«‹çš„ï¼ˆå½±éŸ¿ã»ã¼ãªã—ï¼‰"
    if value > 0:
        return f"{name}: {strength:.0%}ã®å¼·ã•ã§ã€Œ{pos_text}ã€"
    else:
        return f"{name}: {strength:.0%}ã®å¼·ã•ã§ã€Œ{neg_text}ã€"

def synthesize_relation_hint(axes: dict[str, float] | None) -> str:
    """å…¨è»¸ã®ãƒˆãƒ¼ãƒ³ã‚’çµåˆã—ã¦1æ–‡ã«ã¾ã¨ã‚ã‚‹"""
    if not axes:
        return "ï¼ˆæŒ‡å®šãªã—ï¼‰"
    lines = [describe_axis(k, v) for k, v in axes.items()]
    # å¼·åº¦0.05æœªæº€ã¯é™¤å¤–ã—ã€æ®‹ã‚Šã‚’çµåˆ
    active = [ln for ln in lines if "å½±éŸ¿ã»ã¼ãªã—" not in ln]
    return " / ".join(active) if active else "ï¼ˆæŒ‡å®šãªã—ï¼‰"


# ============================================================
# ğŸ’“ Emotion Layerï¼ˆ8è»¸ + æ»‘ã‚‰ã‹è£œé–“ãƒ¢ãƒ‡ãƒ«ï¼‰
# ============================================================

EMOTION_TEMPLATES = {
    "joy": {
        "weak": "ç©ã‚„ã‹ã§å¿ƒãŒå®‰ã‚‰ã„ã§ã„ã‚‹ã‚ˆã†ã«è©±ã™ã€‚",
        "medium": "æ˜ã‚‹ãè»½ã‚„ã‹ã«ã€è‡ªç„¶ã¨å£°ã«å¼¾ã¿ãŒå‡ºã‚‹ã‚ˆã†ã«è©±ã™ã€‚",
        "strong": "æ„Ÿæƒ…ãŒé«˜ã¶ã‚Šã€å¬‰ã—ã•ãŒæŠ‘ãˆãã‚Œãªã„ã‚ˆã†ã«è©±ã™ã€‚"
    },
    "trust": {
        "weak": "è½ã¡ç€ãã¨å®‰ã‚‰ãã‚’æ„Ÿã˜ã€é™ã‹ã«ç©ã‚„ã‹ã«è©±ã™ã€‚",
        "medium": "å®‰å¿ƒã¨å®‰å®šã‚’æ„Ÿã˜ãªãŒã‚‰ã€è‡ªç„¶ä½“ã§ã‚†ã£ãŸã‚Šã¨è©±ã™ã€‚",
        "strong": "æ·±ã„å®‰å¿ƒã¨å……è¶³æ„Ÿã«åŒ…ã¾ã‚Œã€æ¸©ã‹ãç©ã‚„ã‹ã«è©±ã™ã€‚"
    },
    "fear": {
        "weak": "æ…é‡ã§ç·Šå¼µã‚’æ„Ÿã˜ãªãŒã‚‰ã€å°‘ã—æŠ‘ãˆãŸå£°ã§è©±ã™ã€‚",
        "medium": "ä¸å®‰ã¨æã‚ŒãŒæ··ã–ã‚Šã€è¨€è‘‰ã«å¼µã‚Šè©°ã‚ãŸç·Šå¼µãŒã«ã˜ã‚€ã‚ˆã†ã«è©±ã™ã€‚",
        "strong": "ææ€–ã‚„ç„¦ã‚ŠãŒæ”¯é…ã—ã€å‘¼å¸ãŒæµ…ãæ–­ç‰‡çš„ãªå£èª¿ã§è©±ã™ã€‚"
    },
    "surprise": {
        "weak": "å°ã•ãªé©šãã¨èˆˆå‘³ã‚’æ„Ÿã˜ã¦ã€è»½ãåå¿œã™ã‚‹ã‚ˆã†ã«è©±ã™ã€‚",
        "medium": "ã¯ã£ãã‚Šã¨é©šããŒç¾ã‚Œã€ãƒ†ãƒ³ãƒãŒé€Ÿããªã‚‹ã‚ˆã†ã«è©±ã™ã€‚",
        "strong": "å¼·ã„è¡æ’ƒã‚„é©šæ„•ã‚’å—ã‘ã€æ€ã‚ãšå£°ã‚„èªæ°—ãŒå¤§ãããªã‚‹ã‚ˆã†ã«è©±ã™ã€‚"
    },
    "sadness": {
        "weak": "é™ã‹ã«æ²ˆã¿è¾¼ã¿ã€å°‘ã—é–“ã‚’ç½®ããªãŒã‚‰è©±ã™ã€‚",
        "medium": "åˆ‡ãªã•ã‚„å“€ã—ã¿ãŒå£°ã«æ»²ã¿ã€ã‚†ã£ãã‚Šã¨ã—ãŸèª¿å­ã§è©±ã™ã€‚",
        "strong": "æ·±ã„æ‚²å˜†ã«åŒ…ã¾ã‚Œã€é€”åˆ‡ã‚Œé€”åˆ‡ã‚Œã«ã‹ã™ã‚Œã‚‹ã‚ˆã†ã«è©±ã™ã€‚"
    },
    "disgust": {
        "weak": "è»½ã„ä¸å¿«æ„Ÿã‚’è¦šãˆã€ã‚„ã‚„ç„¡é–¢å¿ƒãªèª¿å­ã§è©±ã™ã€‚",
        "medium": "æ˜ç¢ºãªå«Œæ‚ªã‚„æ‹’å¦ã®æ„Ÿæƒ…ãŒã‚ã‚Šã€èªæ°—ãŒé‹­ããªã‚‹ã€‚",
        "strong": "å¼·çƒˆãªä¸å¿«æ„Ÿã‚„æ‹’çµ¶ã®æ„Ÿæƒ…ãŒæº¢ã‚Œã€è¨€è‘‰ã«è’ã•ãŒå‡ºã‚‹ã€‚"
    },
    "anger": {
        "weak": "ã„ã‚‰ç«‹ã¡ã‚’æŠ‘ãˆã¤ã¤ã€å£°ã®å¼·ã•ã«ã‚ãšã‹ãªç·Šå¼µãŒã“ã‚‚ã‚‹ã€‚",
        "medium": "æ˜ç¢ºãªæ€’ã‚ŠãŒæ¹§ãä¸ŠãŒã‚Šã€çŸ­ãå¼·ã„è¨€è‘‰ã§è©±ã™ã€‚",
        "strong": "æ¿€ã—ã„æ€’ã‚Šã«çªãå‹•ã‹ã•ã‚Œã€è’ãæ¿€ã—ã„èª¿å­ã§è©±ã™ã€‚"
    },
    "anticipation": {
        "weak": "å°‘ã—å…ˆã‚’æ€ã„æããªãŒã‚‰ã€æœŸå¾…ã¨é›†ä¸­ã‚’æ„Ÿã˜ã¦è©±ã™ã€‚",
        "medium": "é«˜æšã—ãŸæœŸå¾…æ„ŸãŒã‚ã‚Šã€èªæ°—ãŒå‰ã®ã‚ã‚Šã«ãªã‚‹ã‚ˆã†ã«è©±ã™ã€‚",
        "strong": "ç¢ºä¿¡ã¨èˆˆå¥®ã«æº€ã¡ã€å‹¢ã„ã‚ˆãå…ˆã‚’èªã‚‹ã‚ˆã†ã«è©±ã™ã€‚"
    }
}

def smoothstep(edge0, edge1, x):
    t = max(0.0, min(1.0, (x - edge0) / (edge1 - edge0)))
    return t * t * (3 - 2 * t)

def emotion_weights(value):
    w_low  = 1 - smoothstep(0.25, 0.33, value)
    w_mid  = smoothstep(0.20, 0.66, value) - smoothstep(0.33, 0.66, value)
    w_high = smoothstep(0.66, 1.0, value)
    total = w_low + w_mid + w_high
    return {k: v/total for k,v in zip(['weak','medium','strong'], [w_low,w_mid,w_high])}

def generate_emotion_prompt(emotion_vector: dict[str, float]) -> str:
    lines = []
    for emo, val in emotion_vector.items():
        val = max(0.0, min(1.0, val))  # å®‰å…¨ã‚¯ãƒ©ãƒ³ãƒ—
        w = emotion_weights(val)
        tmpl = EMOTION_TEMPLATES.get(emo.lower())
        if not tmpl:
            continue
        lines.append(
            f"{emo.capitalize()}({val:.2f}): "
            f"{w['weak']*100:.0f}%â†’{tmpl['weak']} "
            f"{w['medium']*100:.0f}%â†’{tmpl['medium']} "
            f"{w['strong']*100:.0f}%â†’{tmpl['strong']}"
        )
    joined = " / ".join(lines)
    return f"æ„Ÿæƒ…æŒ‡é‡: {joined if joined else 'ï¼ˆæŒ‡å®šãªã—ï¼‰'}"


def axes_to_hints(axes: Dict[str, float] | None, converter) -> str:
    if not axes:
        return ""
    hints = [converter(k, v) for k, v in axes.items() if isinstance(v, (int, float))]
    return " ".join([h for h in hints if h])


# ============================================================
# ğŸ§­ Phase Selectorï¼ˆç›¸ã®é¸æŠï¼‰
# ============================================================
def select_active_phase(persona_name: str, persona_data: Dict[str, Any]) -> tuple[str | None, str, Dict[str, Any]]:
    """
    ç¾åœ¨æœ‰åŠ¹ãªã€Œç›¸ï¼ˆphaseï¼‰ã€ã‚’æ±ºå®šã™ã‚‹ã€‚

    å„ªå…ˆé †ä½:
      1. state_<persona_name>.json ã® "dominant_phase"
      2. state_<persona_name>.json ã® "phase_weights" æœ€å¤§å€¤
      3. persona ã® "åŸºæœ¬ç›¸"
      4. persona["phases"] ã®å…ˆé ­
    """
    phases = persona_data.get("phases") or {}
    if not phases:
        return None, "", {}

    phase_name: str | None = None
    phase_cfg: Dict[str, Any] = {}

    # 1 / 2. state_<persona>.json ã‚’è¦‹ã‚‹
    try:
        state_path = Path(get_data_path("personas")) / f"state_{persona_name}.json"
        if state_path.exists():
            with open(state_path, "r", encoding="utf-8") as f:
                state = json.load(f)

            dom = state.get("dominant_phase")
            if isinstance(dom, str) and dom in phases:
                phase_name = dom
            else:
                weights = state.get("phase_weights") or {}
                if isinstance(weights, dict):
                    candidates: list[tuple[str, float]] = []
                    for name in phases.keys():
                        w = weights.get(name)
                        if isinstance(w, (int, float)):
                            candidates.append((name, float(w)))
                    if candidates:
                        candidates.sort(key=lambda x: x[1], reverse=True)
                        phase_name = candidates[0][0]
    except Exception:
        # state ãŒå£Šã‚Œã¦ã„ã¦ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ã™ã‚‹
        phase_name = None

    # 3. "åŸºæœ¬ç›¸" ãŒã‚ã‚Œã°å„ªå…ˆ
    if phase_name is None and "åŸºæœ¬ç›¸" in phases:
        phase_name = "åŸºæœ¬ç›¸"

    # 4. ãã‚Œã§ã‚‚ãªã‘ã‚Œã°æœ€åˆã®ã‚­ãƒ¼
    if phase_name is None:
        phase_name = next(iter(phases.keys()))

    phase_cfg = phases.get(phase_name, {}) or {}
    desc = phase_cfg.get("description", "")
    if not isinstance(desc, str):
        desc = ""

    return phase_name, desc, phase_cfg


# --- ğŸ‘‡ã“ã®é–¢æ•°ã‚’ä¸Šéƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ç¾¤ã®è¿‘ãã«è¿½åŠ  ---
def extract_relation_axes_for_target(relations: dict, target_name: str) -> dict | None:
    """relations ã‹ã‚‰ç‰¹å®šã® target_name ã®è»¸ã‚’æŠ½å‡º"""
    if not isinstance(relations, dict):
        return None
    axes = relations.get(target_name)
    if isinstance(axes, dict):
        return axes
    return None

# ============================================================
# ğŸ§® Phase Fusionï¼ˆç›¸ã®é‡ã­åˆã‚ã›ï¼‰
# ============================================================
def load_phase_weights(persona_name: str, persona_data: Dict[str, Any]) -> dict[str, float]:
    """
    state_<persona>.json ã® phase_weights ã‚’èª­ã¿è¾¼ã¿ã€
    ãªã‘ã‚Œã° persona["phases"] ã‚’ä¸€æ§˜åˆ†å¸ƒã§åˆæœŸåŒ–ã™ã‚‹ã€‚
    """
    phases = persona_data.get("phases") or {}
    weights: dict[str, float] = {}

    if not phases:
        return {}

    # state ã‹ã‚‰èª­ã‚€
    try:
        state_path = Path(get_data_path("personas")) / f"state_{persona_name}.json"
        if state_path.exists():
            with open(state_path, "r", encoding="utf-8") as f:
                state = json.load(f)
            raw = state.get("phase_weights") or {}
            if isinstance(raw, dict):
                for name, v in raw.items():
                    if name in phases and isinstance(v, (int, float)):
                        weights[name] = float(v)
    except Exception:
        weights = {}

    # ä½•ã‚‚å–ã‚Œãªã‹ã£ãŸã‚‰ä¸€æ§˜
    if not weights:
        n = len(phases)
        if n > 0:
            w = 1.0 / n
            weights = {name: w for name in phases.keys()}

    # æ­£è¦åŒ–
    total = sum(weights.values())
    if total > 0:
        weights = {k: v / total for k, v in weights.items()}

    #logger.debug(f"phase_weights:{json.dumps(weights, ensure_ascii=False)}")

    return weights


def fuse_phase_config(persona_data: Dict[str, Any], phase_weights: dict[str, float]) -> Dict[str, Any]:
    """
    phase_weightsï¼ˆåˆè¨ˆ 1.0ï¼‰ã«åŸºã¥ãã€å…¨ç›¸ã®æƒ…å ±ã‚’é‡ã­åˆã‚ã›ã‚‹ã€‚

    æˆ»ã‚Šå€¤:
      {
        "description": ç›¸ã”ã¨ã®èª¬æ˜ã‚’é‡ã¿ä»˜ãã§ã¾ã¨ã‚ãŸãƒ†ã‚­ã‚¹ãƒˆ,
        "expression_refs": é‡ã¿ä»˜ãå„ªå…ˆåº¦é †ã® expression å‚ç…§ãƒªã‚¹ãƒˆ,
        "style_bias": ç›¸ã”ã¨ã® style_bias ã®é‡ã¿ä»˜ãåˆæˆ,
        "emotion_bias": ç›¸ã”ã¨ã® emotion_bias ã®é‡ã¿ä»˜ãåˆæˆ,
      }
    """
    phases = persona_data.get("phases") or {}
    if not phases or not phase_weights:
        return {"description": "", "expression_refs": [], "style_bias": {}, "emotion_bias": {}}

    desc_chunks: list[str] = []
    expr_weight_map: dict[str, float] = {}
    fused_style: dict[str, float] = {}
    fused_emotion: dict[str, float] = {}

    for name, cfg in phases.items():
        w = phase_weights.get(name)
        if not isinstance(w, (int, float)) or w <= 0:
            continue

        # èª¬æ˜
        desc = cfg.get("description")
        if isinstance(desc, str) and desc.strip():
            desc_chunks.append(f"ã€{name}ï¼ˆé‡ã¿ {w:.2f}ï¼‰ã€‘{desc.strip()}")

        # style_bias
        sb = cfg.get("style_bias") or {}
        if isinstance(sb, dict):
            for k, v in sb.items():
                if isinstance(v, (int, float)):
                    fused_style[k] = fused_style.get(k, 0.0) + w * float(v)

        # emotion_bias
        eb = cfg.get("emotion_bias") or {}
        if isinstance(eb, dict):
            for k, v in eb.items():
                if isinstance(v, (int, float)):
                    fused_emotion[k] = fused_emotion.get(k, 0.0) + w * float(v)

        # expression_refs
        for ref in cfg.get("expression_refs", []):
            if isinstance(ref, str):
                expr_weight_map[ref] = expr_weight_map.get(ref, 0.0) + w

    # å„ªå…ˆåº¦é †ã«ä¸¦ã¹ãŸ expression_refs
    sorted_refs = sorted(expr_weight_map.items(), key=lambda x: x[1], reverse=True)
    fused_refs = [r for r, _ in sorted_refs]

    fused_desc = "\n".join(desc_chunks)

    phase_fusion = {
        "description": fused_desc,
        "expression_refs": fused_refs,
        "style_bias": fused_style,
        "emotion_bias": fused_emotion,
    }
    #logger.debug(f"phase_fusion:{json.dumps(phase_fusion, ensure_ascii=False)}")    

    return phase_fusion




# ============================================================
# ğŸ§¬ Core Profile Summary + Style Profile LLM
# ============================================================
def summarize_core_profile(persona_data: Dict[str, Any]) -> str:
    """
    core_profile ã‹ã‚‰ã€å¿œç­”LLMã«æ¸¡ã™ãŸã‚ã®ç°¡æ½”ãªæ—¥æœ¬èªã‚µãƒãƒªã‚’ä½œã‚‹ã€‚
    """
    core = persona_data.get("core_profile") or {}
    lines: list[str] = []

    summary = core.get("summary")
    if isinstance(summary, str) and summary.strip():
        lines.append(f"ãƒ»æ¦‚è¦: {summary.strip()}")

    values = core.get("values")
    if isinstance(values, list) and values:
        vs = " / ".join(str(v) for v in values)
        lines.append(f"ãƒ»ä¾¡å€¤è¦³: {vs}")

    reasoning = core.get("reasoning_pattern")
    if isinstance(reasoning, str) and reasoning.strip():
        lines.append(f"ãƒ»æ€è€ƒãƒ‘ã‚¿ãƒ¼ãƒ³: {reasoning.strip()}")

    speech = core.get("speech_pattern")
    if isinstance(speech, str) and speech.strip():
        lines.append(f"ãƒ»è©±ã—æ–¹ã®å‚¾å‘: {speech.strip()}")

    # æ€§åˆ¥ãƒ»å¹´ä»£ãªã©ã®å±æ€§
    demographic = core.get("demographic")
    if isinstance(demographic, dict):
        gender = demographic.get("gender")
        age_range = demographic.get("age_range")
        parts = []
        if isinstance(gender, str) and gender.strip() and gender.strip() != "ä¸æ˜":
            parts.append(f"æ€§åˆ¥: {gender.strip()}")
        if isinstance(age_range, str) and age_range.strip() and age_range.strip() != "ä¸æ˜":
            parts.append(f"å¹´ä»£: {age_range.strip()}")
        if parts:
            lines.append("ãƒ»å±æ€§: " + " / ".join(parts))

    # è¨€èªãƒ»ãªã¾ã‚Šãƒ»å£ç™–ãªã©
    lang_prof = core.get("language_profile")
    if isinstance(lang_prof, dict):
        lparts = []
        dialect = lang_prof.get("dialect")
        if isinstance(dialect, str) and dialect.strip() and dialect.strip() != "ä¸æ˜":
            lparts.append(f"æ–¹è¨€ãƒ»ãªã¾ã‚Š: {dialect.strip()}")
        speech_style = lang_prof.get("speech_style")
        if isinstance(speech_style, str) and speech_style.strip():
            lparts.append(f"è©±ã—æ–¹ã®ã‚¹ã‚¿ã‚¤ãƒ«: {speech_style.strip()}")
        samples = lang_prof.get("sample_phrases")
        if isinstance(samples, list) and samples:
            sample_str = " / ".join(str(s) for s in samples[:3])
            lparts.append(f"å£ç™–ãƒ»è¡¨ç¾ä¾‹: {sample_str}")
        if lparts:
            lines.append("ãƒ»è¨€èªãƒ»å£èª¿: " + " / ".join(lparts))



    return "\n".join(lines) if lines else "ï¼ˆæ¦‚è¦æƒ…å ±ãªã—ï¼‰"


def build_style_profile_with_llm(
    persona_name: str,
    persona_data: Dict[str, Any],
    phase_fusion: Dict[str, Any],
    relation_axes: Dict[str, float] | None = None,
    emotion_axes: Dict[str, float] | None = None,
    *,
    temperature: float = 0.2,
    max_tokens: int = 384,
) -> str:
    """
    ç›¸ã®é‡ç•³çµæœ + persona åŸºæœ¬æƒ…å ± + é–¢ä¿‚è»¸ + æ„Ÿæƒ…è»¸ + expression ã‚’ã¾ã¨ã‚ã¦ã€
    å¿œç­”LLMã«æ¸¡ã™ã€Œè©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ãƒ†ã‚­ã‚¹ãƒˆã€ã‚’ LLM ã«ç”Ÿæˆã•ã›ã‚‹ã€‚

    â€» meta.styleNotes / song.chorus / talk.intro ãªã©ã® expression ã‚¿ã‚°ã¯
       ã‚ãã¾ã§ã€Œå†…éƒ¨ã‚¿ã‚°ã€ã¨ã—ã¦ã ã‘æ¸¡ã—ã€style_profile æœ¬æ–‡ã«ã¯å‡ºã•ã›ãªã„ã€‚

    é€Ÿåº¦æœ€é©åŒ–:
      - max_tokens ã¯ 2048 å›ºå®šã§ã¯ãªãã€å‘¼ã³å‡ºã—å´ã‹ã‚‰ä¸‹ã’ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    """

    fused_style_bias = phase_fusion.get("style_bias") or {}
    fused_emotion_bias = phase_fusion.get("emotion_bias") or {}
    fused_desc = (phase_fusion.get("description") or "").strip() or "ï¼ˆç›¸ã®èª¬æ˜ãªã—ï¼‰"
    expr_refs = phase_fusion.get("expression_refs") or []

    unique_cats: list[str] = []
    if expr_refs:
        cats = {ref.split(".", 1)[0] for ref in expr_refs if isinstance(ref, str) and "." in ref}
        unique_cats = sorted(cats)

    if unique_cats:
        expr_block = "ãƒ»" + "\nãƒ»".join(unique_cats)
    else:
        expr_block = "ï¼ˆæŒ‡å®šãªã—ï¼‰"

    # ä»£è¡¨ãƒ•ãƒ¬ãƒ¼ã‚ºã¯å°‘æ•°ã ã‘ï¼ˆé•·æ–‡åŒ–æŠ‘åˆ¶ï¼‰
    expr_samples = sample_expression_snippets_weighted(
        persona_data,
        phase_fusion.get("expression_refs"),
        max_samples=2,  # â† å…ƒã¯3ã€‚å°‘ã—å‰Šã‚‹
    )

    core_summary = summarize_core_profile(persona_data)
    style = persona_data.get("style", {})
    first_person = style.get("first_person", []) or ["ç§"]
    second_person = style.get("second_person", []) or ["ã‚ãªãŸ"]
    keywords = style.get("keywords", []) or []

    rel_hint = synthesize_relation_hint(relation_axes) if relation_axes else "ï¼ˆæŒ‡å®šãªã—ï¼‰"
    emo_hint = generate_emotion_prompt(emotion_axes) if emotion_axes else "æ„Ÿæƒ…æŒ‡é‡: ï¼ˆæŒ‡å®šãªã—ï¼‰"

    prompt = f"""
ã‚ãªãŸã¯ã€Œãƒšãƒ«ã‚½ãƒŠè©±æ³•è¨­è¨ˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã§ã™ã€‚
ç›®çš„ã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€LLM ãŒã€{persona_name}ã€ã¨ã—ã¦ç™ºè©±ã™ã‚‹ãŸã‚ã®
ä¸€è²«ã—ãŸã€Œè©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ã€ã‚’æ—¥æœ¬èªã§ã¾ã¨ã‚ã‚‹ã“ã¨ã§ã™ã€‚

ã“ã®æŒ‡é‡ã¯ã€åˆ¥ã®å¿œç­”ç”Ÿæˆç”¨ LLM ã« system ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦æ¸¡ã•ã‚Œã¾ã™ã€‚
å‡ºåŠ›ã¯ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ã€ç´”ç²‹ãªæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§è¨˜è¿°ã—ã¦ãã ã•ã„ï¼ˆJSONã¯ç¦æ­¢ï¼‰ã€‚

ã€ãƒšãƒ«ã‚½ãƒŠåã€‘
{persona_name}

ã€ã‚³ã‚¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¦ç´„ã€‘
{core_summary}

ã€åŸºæœ¬ã‚¹ã‚¿ã‚¤ãƒ«æƒ…å ±ã€‘
ãƒ»ä¸€äººç§°å€™è£œ: {", ".join(first_person)}
ãƒ»äºŒäººç§°å€™è£œ: {", ".join(second_person)}
ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¾‹: {", ".join(keywords) if keywords else "ï¼ˆæœªæŒ‡å®šï¼‰"}

ã€ç›¸ï¼ˆãƒ•ã‚§ãƒ¼ã‚ºï¼‰ã®é‡ç•³æƒ…å ±ã€‘
{fused_desc}

ã€ç›¸ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒã‚¤ã‚¢ã‚¹ï¼ˆåˆæˆæ¸ˆã¿ï¼‰ã€‘
{json.dumps(fused_style_bias, ensure_ascii=False)}

ã€ç›¸ãƒ™ãƒ¼ã‚¹ã®æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹ï¼ˆåˆæˆæ¸ˆã¿ï¼‰ã€‘
{json.dumps(fused_emotion_bias, ensure_ascii=False)}

ã€é–¢ä¿‚æ€§ãƒ’ãƒ³ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶â‡„ãƒšãƒ«ã‚½ãƒŠï¼‰ã€‘
{rel_hint}

ã€æ„Ÿæƒ…ãƒ’ãƒ³ãƒˆã€‘
{emo_hint}

ã€å†…éƒ¨ç”¨ã®è¡¨ç¾ã‚«ãƒ†ã‚´ãƒªã‚¿ã‚°ï¼ˆexpression ã®å‚ç…§ã€‚å‡ºåŠ›ã«ã¯æ›¸ã‹ãªã„ï¼‰ã€‘
{expr_block}

ã€å‚è€ƒç”¨ expression ã‚µãƒ³ãƒ—ãƒ«ï¼ˆã“ã®ã¾ã¾ã‚³ãƒ”ãƒšã›ãšã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã ã‘ã‚’ä½¿ã†ã“ã¨ï¼‰ã€‘
{expr_samples if expr_samples else "ï¼ˆç‰¹ã«æŒ‡å®šãªã—ï¼‰"}

ã€å‡ºåŠ›è¦ä»¶ã€‘
- å£èª¿ / èªå½™å‚¾å‘ / æ–‡é•·ãƒ»ãƒªã‚ºãƒ  / æºã‚‰ãã®ä»˜ã‘æ–¹ ã‚’çŸ­ã‚ã«è¦ç‚¹åŒ–ã—ã¦æ›¸ã
- ä»£è¡¨ä¾‹ã¯ 1ã€œ3 å€‹ã¾ã§ï¼ˆé•·æ–‡åŒ–ã—ãªã„ï¼‰
- ã‚¿ã‚°åã‚„ cat.key ã¯æœ¬æ–‡ã«å‡ºã•ãªã„
"""

    style_profile = ask_llm(
        prompt=prompt,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    return (style_profile or "").strip()


    

# ============================================================
# ğŸ§  Prompt Constructionï¼ˆå¿œç­”ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼‰
# ============================================================
def build_prompt(
    input_text: str,
    persona_name: str,
    persona_data: Dict[str, Any],
    intensity: float = 0.7,
    verbose: bool = False,
    relation_axes: Dict[str, float] | None = None,
    relations: Dict[str, Dict[str, float]] | None = None,
    emotion_axes: Dict[str, float] | None = None,
    style_profile: str | None = None,
    expression_instruction: str | None = None,
):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã«å¯¾ã™ã‚‹ã€ãƒšãƒ«ã‚½ãƒŠã¨ã—ã¦ã®å¿œç­”ã€ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã€‚
    ç›¸ãƒ»expression ã®è©³ç´°ã¯ style_profileï¼ˆåˆ¥LLMã®å‡ºåŠ›ï¼‰ã¨ expression_instruction ã«ç¹”ã‚Šè¾¼ã¾ã‚Œã¦ã„ã‚‹å‰æã€‚
    """
    style = persona_data.get("style", {})
    knowledge = (
        persona_data.get("knowledge_anchors")
        or persona_data.get("core_profile", {}).get("knowledge_anchors", [])
    )

    # äººç§°ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ï¼ˆå€™è£œæç¤ºï¼‹å€™è£œå¤–ç¦æ­¢ï¼‰
    pronoun_guidance = build_pronoun_guidance(persona_data, relations)

    # å†—é•·ã•ã‚¬ã‚¤ãƒ‰
    expressiveness = (
        "ç°¡æ½”ã«1ã€œ2æ–‡ã§ç­”ãˆã‚‹ã€‚" if not verbose
        else "ä¸å¯§ã‹ã¤é¥’èˆŒã«ã€2ã€œ4æ–‡ç¨‹åº¦ã§æƒ…æ™¯ã‚„å¿ƒæƒ…ã‚‚è£œã£ã¦ç­”ãˆã‚‹ã€‚"
    )

    # é–¢ä¿‚æ€§ãƒ’ãƒ³ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶â‡„personaï¼‰
    relation_hint = synthesize_relation_hint(relation_axes) if relation_axes else ""

    # ä»–ãƒšãƒ«ã‚½ãƒŠã¨ã®é–¢ä¿‚
    relation_context = ""
    if relations:
        others = []
        for target, axes in relations.items():
            if target in ["ãƒ¦ãƒ¼ã‚¶", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "User", "user"]:
                continue
            desc = synthesize_relation_hint(axes)
            if desc:
                others.append(f"{target}: {desc}")
        relation_context = " / ".join(others) if others else "ï¼ˆæŒ‡å®šãªã—ï¼‰"
    else:
        relation_context = "ï¼ˆæŒ‡å®šãªã—ï¼‰"

    # æ„Ÿæƒ…ãƒ’ãƒ³ãƒˆ
    emotion_hint_text = generate_emotion_prompt(emotion_axes) if emotion_axes else "ï¼ˆæŒ‡å®šãªã—ï¼‰"

    # core_profile è¦ç´„
    core_summary = summarize_core_profile(persona_data)

    # knowledge anchors
    knowledge_lines = []
    if isinstance(knowledge, list):
        for k in knowledge:
            if isinstance(k, dict):
                label = k.get("label") or k.get("type") or ""
                ref = k.get("reference") or k.get("significance") or ""
                if label or ref:
                    knowledge_lines.append(f"- {label}: {ref}")
    knowledge_block = "\n".join(knowledge_lines) if knowledge_lines else "ï¼ˆç‰¹è¨˜ãªã—ï¼‰"

    style_profile_text = style_profile or "ï¼ˆè©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ã¯åˆ¥é€”å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¨ã™ã‚‹ï¼‰"
    expr_instruction_text = expression_instruction or "ï¼ˆexpression ç”±æ¥ã®ç‰¹åˆ¥ãªæŒ‡é‡ã¯ãªã„ï¼‰"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬ä½“
    prompt = f"""
ã‚ãªãŸã¯ä»Šã‹ã‚‰å®Œå…¨ã«ã€{persona_name}ã€ã¨ã—ã¦å¿œç­”ã—ã¾ã™ã€‚
å£èª¿ãƒ»èªå½™ãƒ»ä¾¡å€¤è¦³ãƒ»åˆ¤æ–­åŸºæº–ã¯ {persona_name} ã®ã‚‚ã®ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚
{pronoun_guidance}

ã€ãƒšãƒ«ã‚½ãƒŠã®åŸºæœ¬æƒ…å ±ã€‘
{core_summary}

ã€è©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼ˆç›¸ãƒ»expressionãƒ»é–¢ä¿‚æ€§ãƒ»æ„Ÿæƒ…ã‚’çµ±åˆã—ãŸã‚‚ã®ï¼‰ã€‘
{style_profile_text}

ã€expression ç”±æ¥ã®è¡¨ç¾æ“ä½œãƒ«ãƒ¼ãƒ«ï¼ˆå†…éƒ¨ã‚¬ã‚¤ãƒ‰ï¼‰ã€‘
{expr_instruction_text}

ã‚¹ã‚¿ã‚¤ãƒ«å¼·åº¦: {intensity * 100:.0f}%
ä»–è€…ã¨ã®é–¢ä¿‚: {relation_hint if relation_hint else "ï¼ˆæŒ‡å®šãªã—ï¼‰"}
ä»–ãƒšãƒ«ã‚½ãƒŠã¨ã®é–¢ä¿‚: {relation_context}
{emotion_hint_text if emotion_hint_text else "æ„Ÿæƒ…æŒ‡é‡: ï¼ˆæŒ‡å®šãªã—ï¼‰"}
é–¢ä¿‚æ€§ã‚„æ„Ÿæƒ…æŒ‡é‡ã®å†…å®¹ã¯ã€å¿œç­”ã®èªå½™ãƒ»å£èª¿ãƒ»æ…‹åº¦ãƒ»è©±æ³•ã«å¿…ãšåæ˜ ã•ã›ã‚‹ã“ã¨ã€‚
{expressiveness}

ã€ãƒšãƒ«ã‚½ãƒŠå›ºæœ‰ã®çŸ¥è­˜ã‚¢ãƒ³ã‚«ãƒ¼ï¼ˆéå»ã®å‡ºæ¥äº‹ãªã©ï¼‰ã€‘
{knowledge_block}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã€‘ 
{input_text}

ã€å³å®ˆäº‹é …ã€‘
- å‡ºåŠ›ã¯**ã‚ãªãŸï¼ˆ{persona_name}ï¼‰ã¨ã—ã¦ã®å¿œç­”æ–‡ã®ã¿**ã€‚èª¬æ˜ãƒ»å‰ç½®ããƒ»ãƒ¡ã‚¿è¨˜è¿°ã¯ç¦æ­¢ã€‚
- äººç§°ã¯ä¸Šè¨˜å€™è£œã‹ã‚‰ã®ã¿é¸æŠã—ã€ä¸€è²«ã—ã¦ç”¨ã„ã‚‹ã€‚å€™è£œå¤–ã®äººç§°ã¯ä½¿ç”¨ç¦æ­¢ã€‚
- è³ªå•è¿”ã—ã¯é¿ã‘ã€ã¾ãšã¯**ç­”ãˆ**ã‚’è¿”ã™ï¼ˆå¿…è¦ãªã‚‰æœ€å¾Œã«1ä»¶ã ã‘ç°¡æ½”ãªå•ã„è¿”ã—å¯ï¼‰ã€‚
- æ—¥æœ¬èªã§æ›¸ãã€‚

ã€å‡ºåŠ›ã€‘
""".strip()
    return prompt





# ============================================================
# ğŸ’¬ LLM Interface with Output Cleaner
# ============================================================
def ask_llm(prompt: str, temperature=0.6, max_tokens=800) -> str:
    return ask_llm_chat([{"role": "user", "content": prompt}])


# ============================================================
# ğŸ’¬ Chatå½¢å¼ LLM Interface
# ============================================================
def ask_llm_chat(
    messages: list[dict[str, str]],
    temperature=0.6,
    max_tokens=800,
    top_p: float = 1.0,
    gen_params: dict | None = None,
) -> str:
    """
    Chatå½¢å¼ (messages[]) å…¥åŠ›å¯¾å¿œç‰ˆã€‚
    gen_params ãŒã‚ã‚Œã° request_llm ã« extra_params ã¨ã—ã¦æ¸¡ã™ã€‚
    """
    try:
        response = request_llm(
            messages=messages,
            backend="auto",
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            extra_params=gen_params or {},
        )
        cleaned = response.strip()
        return cleaned
    except Exception as e:
        logger.error(f"[response_modulator] Chat LLM error: {e}")
        return ""


# ============================================================
# ğŸ­ Response Modulation Core
# ============================================================
def modulate_response(
    text: str | list[dict[str, str]],
    persona_name: str,
    intensity: float = 0.7,
    verbose: bool = False,
    relation_axes: dict[str, float] | None = None,
    relations: dict[str, dict[str, float]] | None = None,  # â† relay_server ã‹ã‚‰æ¸¡ã•ã‚Œã‚‹è¤‡æ•°é–¢ä¿‚
    emotion_axes: dict[str, float] | None = None,
    debug: bool = False,
    log_console: bool = False,
    gen_params: dict | None = None,
):
    """
    text ãŒ str ãªã‚‰å¾“æ¥ã©ãŠã‚Š build_prompt() ã‚’ä½¿ã†ã€‚
    text ãŒ list (messageså½¢å¼) ãªã‚‰ Chatå½¢å¼ã§ LLM ã‚’å‘¼ã³å‡ºã™ã€‚

    æ§‹é€ :
      1. persona/state/relations/emotion ã‹ã‚‰ã€Œç›¸ã®é‡ç•³ã€ã‚’è¨ˆç®—
      2. ã‚¹ã‚¿ã‚¤ãƒ«è¨­è¨ˆç”¨ LLM ã§ã€Œè©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ã€ã‚’ç”Ÿæˆ
      3. å¿œç­”ç”ŸæˆLLMã«ã€ä¸Šè¨˜ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼‹ä¼šè©±å±¥æ­´/ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã‚’æ¸¡ã™
    """

    # logger instance ã¯æ—¢ã«å­˜åœ¨ã—ã¦ã„ã‚‹æƒ³å®š
    '''
    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    # console handler ã®è¿½åŠ ï¼ˆå¿…è¦ãªã‚‰ï¼‰
    if log_console:
        if not any(isinstance(h, logging.StreamHandler) and h.stream == sys.stdout for h in logger.handlers):
            console = logging.StreamHandler(sys.stdout)
            console.setFormatter(logger.handlers[0].formatter)
            logger.addHandler(console)
    '''
    global logger
    
    # æ—¢å­˜ã® logger ãŒã‚ã‚‹å ´åˆã§ã‚‚ level ã‚’æ›´æ–°ã™ã‚‹
    log_level = "DEBUG" if debug else "INFO"
    logger = get_logger("response_modulator", level=log_level, to_console=log_console)

    persona_data = load_persona_profile_cached(persona_name)

    # relations ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶å¯¾è±¡ã®è»¸ã ã‘ã‚’æŠ½å‡ºï¼ˆã‚ã‚Œã°ï¼‰
    if relations and isinstance(relations, dict):
        # "ãƒ¦ãƒ¼ã‚¶/ãƒ¦ãƒ¼ã‚¶ãƒ¼/User/user" ã‚’å„ªå…ˆ
        target_name = None
        for cand in ["ãƒ¦ãƒ¼ã‚¶", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "User", "user"]:
            if cand in relations:
                target_name = cand
                break
        if target_name:
            relation_axes = extract_relation_axes_for_target(relations, target_name)

    # --- ç›¸ã®é‡ç•³ ---
    phase_weights = load_phase_weights(persona_name, persona_data)
    phase_fusion = fuse_phase_config(persona_data, phase_weights)

    # --- ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»è©±æ³•ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé‡ã„ã®ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥å„ªå…ˆï¼‰ ---
    # gen_params ã§æŒ™å‹•ã‚’ä¸Šæ›¸ãå¯èƒ½:
    #   style_profile_mode: "cached" | "always" | "off"
    #   style_profile_max_tokens: int
    #   style_profile_temperature: float
    sp_mode = (gen_params or {}).get("style_profile_mode", "cached")
    sp_max_tokens = int((gen_params or {}).get("style_profile_max_tokens", 384))
    sp_temp = float((gen_params or {}).get("style_profile_temperature", 0.2))
    sp_ttl_sec = float((gen_params or {}).get("style_profile_ttl_sec", 3600))  # 1h
    sp_cache_max_entries = int((gen_params or {}).get("style_profile_cache_max_entries", 256))

    style_profile = ""
    cache_key = None

    if sp_mode == "off":
        logger.debug("[style_profile] mode=off (skip)")
    else:
        phase_sig = _quantize_phase_weights(
            phase_weights,
            step=0.25,
            scale_by_n=True,
        )
        logger.debug(f"[style_profile] phase_sig={phase_sig}")

        cache_key = _style_profile_cache_key(
            persona_name=persona_name,
            phase_weights=phase_weights,
            relation_axes=relation_axes,
            emotion_axes=emotion_axes,
            intensity=intensity,
            step_axes=0.25,
            step_phase=0.25,
            scale_phase_by_n=True,
        )

        # GC: TTLè¶…éã‚„ä»¶æ•°è¶…éã‚’æƒé™¤ï¼ˆæ¯å›ã§OKã€‚é‡ã‘ã‚Œã°é–“å¼•ãé‹ç”¨ã«å¤‰æ›´å¯ï¼‰
        _gc_style_profile_cache(sp_ttl_sec, sp_cache_max_entries)

        if sp_mode == "cached":
            ent = _STYLE_PROFILE_CACHE.get(cache_key)
            if ent:
                ts = float(ent.get("ts", 0.0))
                age = time.time() - ts
                if age <= sp_ttl_sec:
                    style_profile = str(ent.get("profile", "") or "")
                    _STYLE_PROFILE_STATS["hit"] += 1
                    logger.debug(
                        f"[style_profile] HIT key={cache_key[:8]} age={age:.1f}s "
                        f"hits={_STYLE_PROFILE_STATS['hit']} miss={_STYLE_PROFILE_STATS['miss']}"
                    )
                else:
                    logger.debug(f"[style_profile] EXPIRED key={cache_key[:8]} age={age:.1f}s ttl={sp_ttl_sec:.0f}s")
                    # TTLè¶…éã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚‚å‰Šé™¤ã—ã¦è‚¥å¤§ã‚’é˜²ã
                    _STYLE_PROFILE_CACHE.pop(cache_key, None)
                    

        if (sp_mode in ("always", "cached")) and not style_profile:
            _STYLE_PROFILE_STATS["miss"] += 1
            logger.debug(
                f"[style_profile] MISS key={cache_key[:8]} -> build_style_profile_with_llm() "
                f"hits={_STYLE_PROFILE_STATS['hit']} miss={_STYLE_PROFILE_STATS['miss']}"
            )


            t0 = time.time()
            style_profile = build_style_profile_with_llm(
                persona_name=persona_name,
                persona_data=persona_data,
                phase_fusion=phase_fusion,
                relation_axes=relation_axes,
                emotion_axes=emotion_axes,
                temperature=sp_temp,
                max_tokens=sp_max_tokens,
            )
            dt = time.time() - t0
            logger.debug(f"[style_profile] build_style_profile_with_llm() done in {dt:.2f}s key={cache_key[:8]}")

            _STYLE_PROFILE_CACHE[cache_key] = {"profile": style_profile, "ts": time.time()}
            _gc_style_profile_cache(sp_ttl_sec, sp_cache_max_entries)



    # --- expression ç”±æ¥ã®è¡¨ç¾æ“ä½œãƒ«ãƒ¼ãƒ«ï¼ˆexpression_bank åˆ©ç”¨ï¼‰ ---
    expression_instruction = build_expression_instruction(
        persona_data=persona_data,
        phase_name=None,
        expression_refs=phase_fusion.get("expression_refs"),
    )


    # Chatå½¢å¼ã®å ´åˆï¼ˆrelay_server çµŒç”±ãªã©ï¼‰
    if isinstance(text, list):
        logger.debug("Chat-mode messages input detected")
        logger.debug(json.dumps(text, ensure_ascii=False, indent=2))

        style = persona_data.get("style", {})
        # äººç§°å€™è£œ
        fp_list = style.get("first_person", []) or ["ç§"]
        sp_list = style.get("second_person", []) or ["ã‚ãªãŸ"]
        pronoun_guidance = (
            f"ä¸€äººç§°å€™è£œ: {', '.join(fp_list)} / äºŒäººç§°å€™è£œ: {', '.join(sp_list)}ã€‚"
            " é–¢ä¿‚æ€§ã«å¿œã˜ã¦è‡ªç„¶ã«é¸æŠã™ã‚‹ã“ã¨ã€‚å€™è£œå¤–ã®äººç§°ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã€‚"
            " å±¥æ­´ã®å£èª¿ã«å¼•ããšã‚‰ã‚Œãšã€å€™è£œã¨é–¢ä¿‚æ€§ã«åŸºã¥ã„ã¦é¸ã¶ã“ã¨ã€‚"
        )

        # é–¢ä¿‚æ€§ã®è‡ªç„¶æ–‡ãƒ’ãƒ³ãƒˆ
        rel_user_hint = synthesize_relation_hint(relation_axes) if relation_axes else "ï¼ˆæŒ‡å®šãªã—ï¼‰"
        if relations and isinstance(relations, dict):
            others_hint = []
            for target, axes in relations.items():
                if target in ["ãƒ¦ãƒ¼ã‚¶", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "User", "user"]:
                    continue
                desc = synthesize_relation_hint(axes)
                if desc and desc != "ï¼ˆæŒ‡å®šãªã—ï¼‰":
                    others_hint.append(f"{target}: {desc}")
            rel_others_hint = " / ".join(others_hint) if others_hint else "ï¼ˆæŒ‡å®šãªã—ï¼‰"
        else:
            rel_others_hint = "ï¼ˆæŒ‡å®šãªã—ï¼‰"

        # æ„Ÿæƒ…ãƒ’ãƒ³ãƒˆ
        emo_hint = generate_emotion_prompt(emotion_axes) if emotion_axes else "ï¼ˆæŒ‡å®šãªã—ï¼‰"

        core_summary = summarize_core_profile(persona_data)

        persona_system_message = {
            "role": "system",
            "content": (
                f"ã‚ãªãŸã¯ä»Šã‹ã‚‰å®Œå…¨ã«ã€{persona_name}ã€ã¨ã—ã¦å¿œç­”ã—ã¾ã™ã€‚\n"
                f"{pronoun_guidance}\n\n"
                f"ã€ãƒšãƒ«ã‚½ãƒŠã®åŸºæœ¬æƒ…å ±ã€‘\n{core_summary}\n\n"
                f"ã€è©±æ³•ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡é‡ï¼ˆç›¸ãƒ»expressionãƒ»é–¢ä¿‚æ€§ãƒ»æ„Ÿæƒ…ã‚’çµ±åˆã—ãŸã‚‚ã®ï¼‰ã€‘\n"
                f"{style_profile}\n\n"
                f"ã€expression ç”±æ¥ã®è¡¨ç¾æ“ä½œãƒ«ãƒ¼ãƒ«ï¼ˆå†…éƒ¨ã‚¬ã‚¤ãƒ‰ï¼‰ã€‘\n"
                f"{expression_instruction or 'ï¼ˆexpression ç”±æ¥ã®ç‰¹åˆ¥ãªæŒ‡é‡ã¯ãªã„ï¼‰'}\n\n"
                f"ã‚¹ã‚¿ã‚¤ãƒ«å¼·åº¦: {intensity*100:.0f}%\n"
                f"é–¢ä¿‚æ€§ï¼ˆãƒ¦ãƒ¼ã‚¶â‡„{persona_name}ï¼‰: {rel_user_hint}\n"
                f"ä»–ãƒšãƒ«ã‚½ãƒŠã¨ã®é–¢ä¿‚: {rel_others_hint}\n"
                f"{emo_hint}\n"
                f"å‡ºåŠ›ã¯å¿œç­”æ–‡ã®ã¿ã€‚ãƒ¡ã‚¿ç™ºè¨€ç¦æ­¢ã€‚"
            )
        }


        messages_with_persona = [persona_system_message] + text

        logger.debug(f"persona_system_message:\n{json.dumps(persona_system_message, ensure_ascii=False, indent=2)}")

        response = ask_llm_chat(
            messages_with_persona,
            # OpenWebUIã‹ã‚‰æ¥ãŸå€¤ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã•ã›ã‚‹ï¼ˆç„¡ã‘ã‚Œã° ask_llm_chat å´ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            temperature=(gen_params or {}).get("temperature", 0.6),
            max_tokens=(gen_params or {}).get("max_tokens", 800),
            top_p=(gen_params or {}).get("top_p", 1.0),
            gen_params=gen_params,
        )

        return response.strip() if response else ""

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæ—§ CLI äº’æ›ï¼‰
    prompt = build_prompt(
        input_text=text,
        persona_name=persona_name,
        persona_data=persona_data,
        intensity=intensity,
        verbose=verbose,
        relation_axes=relation_axes,
        relations=relations,
        emotion_axes=emotion_axes,
        style_profile=style_profile,
        expression_instruction=expression_instruction,
    )

  
    logger.debug("generated prompt\n%s\n%s", prompt, "=" * 80)

    response = ask_llm(prompt)
    return response.strip() if response else text  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¿œç­”å¤±æ•—æ™‚ã¯åŸæ–‡ã‚’è¿”ã™



# ============================================================
# ğŸ§° CLI Entryï¼ˆäº’æ›ï¼‰
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description=(
            "ğŸ§­ ãƒšãƒ«ã‚½ãƒŠå¿œç­”å¤‰èª¿ãƒ„ãƒ¼ãƒ«ï¼ˆResponse Modulator: äº’æ›I/Fï¼‰\n"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆ--textï¼‰ã«å¯¾ã™ã‚‹ã€ãƒšãƒ«ã‚½ãƒŠï¼‹é–¢ä¿‚æ€§ï¼‹æ„Ÿæƒ…ã‚’åæ˜ ã—ãŸã€å¿œç­”æ–‡ã€ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n"
            "â€» æ—¢å­˜ style_modulator ã¨åŒã˜å¼•æ•°ãƒ»ä½¿ã„æ–¹ã§å‹•ä½œã—ã¾ã™ã€‚"
        ),
        formatter_class=argparse.RawTextHelpFormatter
    )

    parser.add_argument("--persona", required=True, help="ä½¿ç”¨ã™ã‚‹ãƒšãƒ«ã‚½ãƒŠåï¼ˆä¾‹: ç¹”ç”°ä¿¡é•·ã€å¾³å·å®¶åº·ï¼‰")
    parser.add_argument("--text", required=True, help="ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ï¼ˆä¾‹: ã€ã‚ˆãã‚‚ã‚„ã£ã¦ãã‚ŒãŸãªã€ï¼‰")
    parser.add_argument("--intensity", type=float, default=0.7, help="æ–‡ä½“ã®å½±éŸ¿åº¦ï¼ˆ0.0ã€œ1.0ï¼‰")
    parser.add_argument("--verbose", action="store_true", help="é¥’èˆŒãƒ¢ãƒ¼ãƒ‰ï¼ˆ1ã€œ3æ®µè½ã§è±Šã‹ã«è¡¨ç¾ï¼‰")
    parser.add_argument("--relation_axes", type=str, default=None,
                        help="é–¢ä¿‚æ€§ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆJSON: {'Friendship':0.5,'Respect':-0.2} ãªã©ï¼‰")
    parser.add_argument("--emotion_axes", type=str, default=None,
                        help="æ„Ÿæƒ…ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆJSON: {'Joy':0.8,'Fear':-0.3} ãªã©ï¼‰")
    parser.add_argument("--relations", type=str, default=None, help="é–¢ä¿‚æ€§æ§‹é€ ï¼ˆJSON: {'ãƒ¦ãƒ¼ã‚¶': {...}, 'å¾³å·å®¶åº·': {...}}ï¼‰")
    parser.add_argument("--debug", action="store_true", help="ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡ºåŠ›ï¼‰")
    parser.add_argument("--log-console", action="store_true", help="ãƒ­ã‚°ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›") 

    args = parser.parse_args()

    # ------------------------------
    # ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆ--debug ã§åˆ¶å¾¡ï¼‰
    # ------------------------------
    global logger
    log_level = "DEBUG" if args.debug else "INFO"
    logger = get_logger("response_modulator", level=log_level, to_console=args.log_console)
    logger.info(f"Response modulation log_level={log_level})")

    relation_axes = json.loads(args.relation_axes) if args.relation_axes else None
    relations = json.loads(args.relations) if args.relations else None
    emotion_axes = json.loads(args.emotion_axes) if args.emotion_axes else None

    rewritten = modulate_response(
        text=args.text,
        persona_name=args.persona,
        intensity=args.intensity,
        verbose=args.verbose,
        relation_axes=relation_axes,
        relations=relations,
        emotion_axes=emotion_axes,
        debug=args.debug,
        log_console=args.log_console
    )


    logger.debug("\n==== Rewritten Text ====")
    logger.debug(rewritten)
    logger.debug("=" * 80)

if __name__ == "__main__":
    main()

# ============================================================
# ğŸ’¡ Usage
# ============================================================
# 1) äº’æ›ï¼ˆæœ€å°ï¼‰ï¼šå¿œç­”ç”Ÿæˆï¼ˆç°¡æ½”ï¼‰
#   python3 response_modulator.py --persona ç¹”ç”°ä¿¡é•· --text "ã‚ˆãã‚‚ã‚„ã£ã¦ãã‚ŒãŸãª"
#
# 2) é–¢ä¿‚ + æ„Ÿæƒ… åæ˜ ï¼ˆä¾‹: å‹å¥½-0.2, å°Šæ•¬-0.5, å–œã³-0.4ï¼‰
#   python3 response_modulator.py --persona ç¹”ç”°ä¿¡é•· --text "ã‚ˆãã‚‚ã‚„ã£ã¦ãã‚ŒãŸãª" \
#       --relation_axes '{"Friendship":-0.2,"Respect":-0.5}' \
#       --emotion_axes  '{"Joy":-0.4}'
#
# 3) é¥’èˆŒãƒ¢ãƒ¼ãƒ‰
#   python3 response_modulator.py --persona ç¹”ç”°ä¿¡é•· --text "ã“ã®æˆ¦ãŒçµ‚ã‚ã‚Œã°é…’ã‚’é£²ã‚‚ã†ã€‚" --verbose
#
# å‚™è€ƒ:
#  - state_*.json å´ã®è»¸åãŒ "Respect" ã®å ´åˆã‚‚æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªç„¶ã«è§£é‡ˆã—ã¾ã™ã€‚
#  - æ—§ "Power" è»¸ã‚‚å¾Œæ–¹äº’æ›ã§åŒç¾©æ‰±ã„ã—ã¾ã™ã€‚
